{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 2: Elliptic PDEs, Poissonâ€™s Equation, and a Two-Point Boundary Value Problem \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Creative Commons License Information\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc/4.0/80x15.png\" /></a><br /><span xmlns:dct=\"http://purl.org/dc/terms/\" property=\"dct:title\">Introduction to Partial Differential Equations: Theory and Computations</span> by <a xmlns:cc=\"http://creativecommons.org/ns#\" href=\"https://github.com/CU-Denver-MathStats-OER/Intro-PDEs-Theory-and-Computations\" property=\"cc:attributionName\" rel=\"cc:attributionURL\">Troy Butler</a> is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\">Creative Commons Attribution-NonCommercial 4.0 International License</a>.<br />Based on a work at <a xmlns:dct=\"http://purl.org/dc/terms/\" href=\"https://github.com/CU-Denver-MathStats-OER/Intro-PDEs-Theory-and-Computations\" rel=\"dct:source\">https://github.com/CU-Denver-MathStats-OER/Intro-PDEs-Theory-and-Computations</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.4: A Brief Tutorial on Adjoint-Based A Posteriori Error Analysis\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Section 2.4.1: A forward (finite dimensional linear) problem and computational error\n",
    "---\n",
    "\n",
    "Suppose $A\\in\\mathbb{R}^{n\\times n}$, $b\\in\\mathbb{R}^n$, and the goal is to determine $x\\in\\mathbb{R}^n$ such that \n",
    "\n",
    "$$\n",
    "    \\large Ax = b.\n",
    "$$\n",
    "\n",
    "Here, $x$ is the vector of states, $A$ describes the relations between the states, and $b$ is the data.\n",
    "\n",
    "- The reason we use the more standard linear algebra notation $Ax=b$ compared to the notation of $Av=b$ from [Section 2.2](Chp2Sec2.ipynb) is that we want to think of the matrix-vector problem more generally instead of being derived from the discretization of a differential equation. \n",
    "\n",
    "  While the contents of this notebook are quite general, we will make explicit connections to the $Av=b$ problem and its continuous counterpart throughout this notebook.\n",
    "\n",
    "- ***In practice, we use numerical algorithms to generate a numerical solution $\\hat{x}\\approx x$.***\n",
    "\n",
    "  - In the context of the problem $Av=b$ from [Section 2.2](Chp2Sec2.ipynb), this means that we generate an approximation $\\hat{v}\\approx v$. \n",
    "  \n",
    "    Recall that $\\hat{v}$ is the *exact* numerical solution to $Av=b$, which is an approximation to the *continuous* solution satisfying $Lu=f$ using the notation from [Section 2.3](Chp2Sec3.ipynb). However, we often resort to approximating $\\hat{v}$ on a computer so that we obtain some $\\hat{v}\\approx v$ such that $A\\hat{v}\\approx b$. \n",
    "    \n",
    "    Thus, $\\hat{v}_j$ is an approximation to $v_j$ that is itself an approximation to $u(x_j)$. \n",
    "    \n",
    "    The approximation error in $v_j\\approx u(x_j)$ comes from the finite difference method and is referred to as a discretization error. The approximation error in $\\hat{v}_j\\approx v_j$ comes from using inexact numerical methods for solving $Ax=b$ and is referred to as a **computational error**. Thus, there are two sources of error in the approximation $\\hat{v}_j\\approx u(x_j)$ computing from discretization and computational sources.\n",
    "    \n",
    "- [Section 2.3](Chp2Sec3.ipynb) focused on analyzing the *discretization* error. In this notebook, we focus on quantifying the computational error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Quantifying computational error: uncomputable and computable forms\n",
    "---\n",
    "\n",
    "Having computed an approximate $\\hat{x}$, the generally ***uncomputable*** error is \n",
    "\n",
    "$$\n",
    "\\large e := x-\\hat{x}.\n",
    "$$\n",
    "\n",
    "Why is this error, in general, uncomputable? Well, if we knew what $x$ was, then why did we bother computing $\\hat{x}$? In general, we have no idea what $x$ is, which is why we had to compute $\\hat{x}$ resulting in computational error polluting this solution. This means that the error, $e$, is defined in terms of a quantity $x$ that is not known/uncomputable. \n",
    "\n",
    "However, notice that the residual \n",
    "\n",
    "$$\n",
    "\\large R := b-A\\hat{x}\n",
    "$$\n",
    "\n",
    "is ***computable***. This is, in a sense, a measure of how well the computed solution $\\hat{x}$ satisfies the forward problem $Ax=b$. Unfortunately, given some norm on $\\mathbb{R}^n$, $R$ may be *small* even when $e$ is *large*.\n",
    "\n",
    "Note that the *generally unknown exact solution $x$* satisfies the forward problem *exactly* so that $b=Ax$ meaning that \n",
    "\n",
    "$$\n",
    "\\large R = Ax-A\\hat{x} = A(x-\\hat{x})=Ae.\n",
    "$$\n",
    "\n",
    "We make use of this below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Section 2.4.2: Quantities of interest\n",
    "---\n",
    "\n",
    "We are often motivated to solve problems in order to compute a relatively small number of scalar ***Quantities of Interest (QoI)*** from the solution that correspond to important physical quantities. \n",
    "Many times, these QoI can be written as [linear functionals](https://en.wikipedia.org/wiki/Linear_form) of the solution. \n",
    "We then do not care so much about what the general error, given by $e$, is in the numerical solution compared to how this error ***impacts*** the computed QoI that uses the numerical solution.\n",
    "For the sake of simplicity, assume we care about a single QoI that we denote by $Q$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### [The Riesz Representation Theorem](https://en.wikipedia.org/wiki/Riesz_representation_theorem)\n",
    "\n",
    "> If $Q$ is linear functional of $x$, then there exists $\\psi\\in\\mathbb{R}^n$ such that\n",
    "<br><br>\n",
    "$$\n",
    "   \\large Q(x) = \\left< x, \\psi \\right>.\n",
    "$$\n",
    "<br>\n",
    "Here, $\\left<\\cdot,\\cdot\\right>$ is the usual inner product on $\\mathbb{R}^n$. \n",
    "\n",
    "---\n",
    "\n",
    "With the Riesz Representation Theorem, we exploit the linearity of the inner product to write the error that we care about in the QoI as\n",
    "\n",
    "$$\n",
    "\\large \\begin{eqnarray*}\n",
    "          e_Q &:=& \\large Q(x)-Q(\\hat{x}) \\\\ \\\\\n",
    "               &=&  \\large \\left<x,\\psi\\right> - \\left<\\hat{x},\\psi\\right> \\\\ \\\\\n",
    "               &=&  \\large  \\left<x-\\hat{x},\\psi\\right> \\\\ \\\\\n",
    "               &=&  \\large \\underbrace{\\left<e,\\psi\\right>}_{\\text{uncomputable}}.\n",
    "    \\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "Uncomputable representations may be useful in theoretical settings, but in general, they have no practical utility. We seek to turn an uncomputable quantity into a computable quantity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### The adjoint problem\n",
    "---\n",
    "\n",
    "We define the adjoint problem as\n",
    "\n",
    "$$\n",
    "\\large A^\\top \\phi = \\psi.\n",
    "$$\n",
    "\n",
    "Here, $A^\\top$ denotes the adjoint of the matrix $A$, which, in the case of a real-valued matrix, is given by the transpose.\n",
    "\n",
    "- ***Note that the data of the adjoint problem is determined by the QoI, and the structure of the adjoint operator is determined by the forward problem.***\n",
    "\n",
    "- We suppose that we solve the adjoint problem ***exactly*** to obtian $\\phi$ (we return to this assumption below). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### A computable a posteriori error (estimate) for $e_Q$\n",
    "---\n",
    "\n",
    "We now exploit properties of the inner product and use the adjoint problem.\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "    \\large \\underbrace{\\left<e,\\psi\\right>}_{\\text{uncomputable}} &=&  \\large \\left<e,A^\\top\\phi\\right>  \\\\ \\\\\n",
    "               &=&  \\large  \\left<Ae,\\phi\\right> \\\\ \\\\\n",
    "               &=&  \\large \\underbrace{\\left<R,\\phi\\right>}_{\\text{computable}}.\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "We have derived a computable form of the a posteriori error that takes the form of the residual, $R$, weighted by the adjoint solution, $\\phi$.\n",
    "\n",
    "In general, we do not have the exact solution to the adjoint problem, $\\phi$, but rather a numerical estimate, $\\hat{\\phi}\\approx\\phi$.\n",
    "Replacing $\\phi$ with $\\hat{\\phi}$ results in a computable a posteroiri ***estimate*** given by\n",
    "\n",
    "$$\n",
    "    \\large e_Q \\approx \\left<R, \\hat{\\phi}\\right>. \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Section 2.4.3: Exploration in Python\n",
    "---\n",
    "\n",
    "We use `numpy` so that we can work with arrays (matrices and vectors), and `scipy` for performing certain scientific computations in our example below. \n",
    "The library `matplotlib` is used for creating some visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import scipy.sparse as sparse\n",
    "import scipy.sparse.linalg as splinalg\n",
    "import scipy.linalg as linalg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### A familiar forward problem\n",
    "---\n",
    "\n",
    "Consider the 2-pt BVP\n",
    "\n",
    "$$\n",
    "    \\large u'' = e^{\\alpha x}, \\ x\\in(0,1), \\ u(0)=u(1)=0.\n",
    "$$\n",
    "\n",
    "Here, $\\alpha$ is some parameter. \n",
    "We will play around with different values of this parameter below. \n",
    "\n",
    "We use the standard three-point centered finite difference scheme from [Section 2.2](Chp2Sec2.ipynb) on a uniform mesh of $(0,1)$ with grid spacing $h=0.05$ to discretize this problem into a matrix-vector problem of the form\n",
    "\n",
    "$$\n",
    "    \\large Av = b, \n",
    "$$\n",
    "\n",
    "where $v$ is a vector of nodal values that approximate the solution $u$ at the grid points of the mesh.\n",
    "\n",
    "- ***We are interested in $v$ not $u$ here. We simply use the differential equation to motivate the matrix-vector problem.***\n",
    "\n",
    "- Since most entries in $A$ are zero, we store it as a sparse matrix to give students a better idea of implementation methods utilized for \"larger\" problems involving potentially hundreds of millions of degrees of freedom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Setup computational grid\n",
    "alpha = 10.0  # Try 0.0 and 10.0\n",
    "h = .05\n",
    "xval = np.arange(h, 1.0, h)  # Another way to get an array of interior points\n",
    "num_pts = len(xval)\n",
    "\n",
    "print(xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Discretize BVP \n",
    "\n",
    "# Step 1: Define data b\n",
    "# Uniform grid so can move h to right hand side\n",
    "b = h**2*np.exp(alpha*xval)\n",
    "\n",
    "# Step 2: Define matrix A\n",
    "# We use the spdiags command to map -1 2 1 to the tridiagonal matrix A\n",
    "temp = np.hstack((-np.ones((num_pts,1)), 2.0*np.ones((num_pts,1)), -np.ones((num_pts,1)))).transpose()\n",
    "A = sparse.spdiags(temp, [-1,0,1], num_pts, num_pts, format = \"csr\")\n",
    "print(A)  # Notice how A only \"points to\" the nonzero entries in it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Solving the forward problem where computatoinal error is nontrivial\n",
    "---\n",
    "\n",
    "We approximate the solution $\\hat{v}\\approx v$ by using seven iterations of the conjugate gradient method with no preconditioner (see https://en.wikipedia.org/wiki/Conjugate_gradient_method for more details on this method). \n",
    "\n",
    "We also obtain the \"exact\" $v$ by performing a direct solve (this technically results in an approximation to $v$ but for this problem the computational error in this approximation is negligible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute the approximate solution with CG method\n",
    "(v_approx,_) = splinalg.cg(A, b,tol=1.0e-20, maxiter=7)\n",
    "\n",
    "# Compute the \"exact\" solution\n",
    "v = splinalg.spsolve(A,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Defining some QoI\n",
    "---\n",
    "\n",
    "We assume we are interested in two QoI that are motivated by the continuous BVP:\n",
    "- $Q_1(v) = v_9$ (the 10*th* component of $v$ approximates $u(0.5)$)\n",
    "\n",
    "- $Q_2(v) = 0.2\\sum_{j=11}^{14} v_j$ (this weighted sum approximates the average value of $u$ over $[0.6,0.8]$)\n",
    "\n",
    "We see that these QoI correspond to inner products of $v$ with $\\psi_1$ and $\\psi_2$ where\n",
    "- $\\psi_{1,j} = 1$ if $j=9$ otherwise $\\psi_{1,j}=0$\n",
    "\n",
    "- $\\psi_{2,j}=0.2$ if $j=11,\\ldots,14$ otherwise $\\psi_{2,j}=0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Define the adjoint data vectors\n",
    "psi_1 = np.zeros((num_pts,1))\n",
    "psi_1[9] = 1\n",
    "\n",
    "psi_2 = np.zeros((num_pts,1))\n",
    "psi_2[11:15] = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Setup and solve the adjoint problems\n",
    "---\n",
    "\n",
    "We need to solve\n",
    "\n",
    "$$\n",
    "\\large A^\\top \\phi_1 = \\psi_1, \\ \\text{ and } \\ A^\\top\\phi_2 = \\psi_2.\n",
    "$$\n",
    "\n",
    "We solve the adjoint problems \"exactly\" using a direct solver. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "phi_1 = splinalg.spsolve(A,psi_1)\n",
    "\n",
    "phi_2 = splinalg.spsolve(A,psi_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### The adjoint solutions and a reliable a posteriori error estimate\n",
    "---\n",
    "\n",
    "We now compute the errors in the two QoI using the computed values of `\\hat{v}` and `v` and compare to the computable a posteriori estimates. \n",
    "\n",
    "Recall that the a posteriori error estimates take the form of a residual weighted by the adjoint solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "R = b - A.dot(v_approx)  # The residual\n",
    "\n",
    "err_est_1 = np.dot(R, phi_1)  # Error estimate for Q_1\n",
    "print(err_est_1)\n",
    "\n",
    "err_1 = v[9] - v_approx[9]  # \"Exact error\"\n",
    "print(err_1)\n",
    "\n",
    "print('-'*50) \n",
    "\n",
    "err_est_2 = np.dot(R, phi_2)  # Error estimate for Q_2\n",
    "print(err_est_2)\n",
    "\n",
    "err_2 = np.sum(v[11:15]-v_approx[11:15])*0.2\n",
    "print(err_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Analyzing the results\n",
    "---\n",
    "\n",
    "When working with manufactured solutions, we like to check that the ***effectivity ratio*** of the error estimate defined by the ratio of the error estimate to the actual error is close to one (assuming the actual error is not zero).\n",
    "\n",
    "We can also plot solutions and study the local error contributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "eff_1 = err_est_1/err_1\n",
    "print('Effectivity ratio of 1st error estimate: ', eff_1)\n",
    "\n",
    "print('-'*50)\n",
    "\n",
    "eff_2 = err_est_2/err_2\n",
    "print('Effectivity ratio of 2nd error estimate: ', eff_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "plt.figure(0)\n",
    "plt.plot(xval, v_approx, 'b*', xval, v, 'r-')\n",
    "plt.legend(['$\\hat{v}$','$v$'])\n",
    "\n",
    "# Influence functions: Adjoint solutions\n",
    "plt.figure(1)\n",
    "plt.plot(xval, phi_1, xval, phi_2)\n",
    "plt.legend([r'$\\phi_1$',r'$\\phi_2$'])\n",
    "\n",
    "# \"Local Error Contributions\"\n",
    "plt.figure(2)\n",
    "plt.plot(xval, v-v_approx, xval, R*phi_1, xval, R*phi_2)\n",
    "plt.legend(['$e(x)$', '$R\\phi_1$', '$R\\phi_2$'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Section 2.4.4: Sensitivity analysis (a natural extension)\n",
    "---\n",
    "\n",
    "The data above depends upon the choice of $\\alpha$. \n",
    "In general, $A$ and $b$ may both depend upon some parameters that we collect into a vector we denote $\\lambda\\in\\mathbb{R}^m$.\n",
    "In other words, the problem is written as\n",
    "\n",
    "$$\n",
    "    \\large A(\\lambda)v(\\lambda)= b(\\lambda), \n",
    "$$\n",
    "\n",
    "where clearly the solution $v$ depends upon the parameter (vector) $\\lambda$, so we write $v(\\lambda)$.\n",
    "Subsequently, $Q(v)$ also depends implicitly upon the parameter $\\lambda$, and we write $Q(\\lambda)$ to make this dependence explicit.\n",
    "Since parameters are often subject to uncertainty, we are commonly interested in the sensitivity of the QoI with respect to perturbations in these parameters. \n",
    "\n",
    "Let $\\lambda_i$ denote the $i$th component of the vector $\\lambda$ for $1\\leq i\\leq m$.\n",
    "Then, differentiating $A(\\lambda)v(\\lambda) = b(\\lambda)$ with respect to $\\lambda_i$ and following a similar set of steps as used to derive the computable error estimate, we arrive at\n",
    "\n",
    "$$\n",
    " \\large\t\\partial_{\\lambda_i} Q(\\lambda) = \\left< \\partial_{\\lambda_i} {b}(\\lambda) - \\left[\\partial_{\\lambda_i}A(\\lambda)\\right] {v}(\\lambda), {\\phi}(\\lambda) \\right>.\n",
    "$$\n",
    "\n",
    "Here, $\\phi(\\lambda)$ depends upon $\\lambda$ since $A^\\top$ now also depends upon $\\lambda$. \n",
    "However, we only require the partial derivatives of the data and operator $A$ with respect to the parameters in order to determine the partial derivatives of $Q$. \n",
    "In other words, we solve ***two problems: the forward and adjoint problem*** and are able to determine the gradient of $Q$ even if $\\lambda$ has dimension in the millions. \n",
    "\n",
    "This implementation is left for the inspired/motivated student, but is also a topic we consider in a more advanced PDE course where we also consider how to formulate the adjoint to the differential operator denoted by $L$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Navigation:\n",
    "\n",
    "- [Previous](Chp2Sec3.ipynb)\n",
    "\n",
    "- [Next](Chp2Sec5.ipynb)\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
