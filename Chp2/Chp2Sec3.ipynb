{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35f0008-703a-433c-9bb3-167b49f641fb",
   "metadata": {},
   "source": [
    "# Introduction to Partial Differential Equations\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e7c3e6-799f-42e3-89e3-83e184341f28",
   "metadata": {},
   "source": [
    "## Chapter 2: Elliptic PDEs, Poissonâ€™s Equation, and a Two-Point Boundary Value Problem \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc110bea-24c0-4a4c-974b-b08d6fff2575",
   "metadata": {},
   "source": [
    "## Want to use Colab? [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/CU-Denver-MathStats-OER/Intro-PDEs-Theory-and-Computations/blob/main/Chp2/Chp2Sec3.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c066bf71-c513-460e-ab79-60a0c64c22e2",
   "metadata": {},
   "source": [
    "## Prepping the environment for interactive plots in Colab\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cfe076-939a-4059-972c-8928e10c515d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    print('Running on CoLab - installing missing packages')\n",
    "    !pip install ipympl\n",
    "    from IPython.display import clear_output\n",
    "    clear_output()\n",
    "    exit()\n",
    "else:\n",
    "    print('Not running on CoLab - assuming environment has necessary packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c285c95c-1f05-46a9-a961-3c1a553108f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    from google.colab import output\n",
    "    output.enable_custom_widget_manager()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a91605-68e5-4cba-9474-5557fc15b980",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Creative Commons License Information\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc/4.0/80x15.png\" /></a><br /><span xmlns:dct=\"http://purl.org/dc/terms/\" property=\"dct:title\">Introduction to Partial Differential Equations: Theory and Computations</span> by <a xmlns:cc=\"http://creativecommons.org/ns#\" href=\"https://github.com/CU-Denver-MathStats-OER/Intro-PDEs-Theory-and-Computations\" property=\"cc:attributionName\" rel=\"cc:attributionURL\">Troy Butler</a> is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\">Creative Commons Attribution-NonCommercial 4.0 International License</a>.<br />Based on a work at <a xmlns:dct=\"http://purl.org/dc/terms/\" href=\"https://github.com/CU-Denver-MathStats-OER/Intro-PDEs-Theory-and-Computations\" rel=\"dct:source\">https://github.com/CU-Denver-MathStats-OER/Intro-PDEs-Theory-and-Computations</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9de3d6c-3b15-410d-8160-ba4c6a0969a6",
   "metadata": {},
   "source": [
    "## Section 2.3: Properties of Continuous and Discrete Solutions\n",
    "---\n",
    "\n",
    "For simplicity, we consider the domain $(0,1)$ here as opposed to [Section 2.1](Chp2Sec1.ipynb) that focused on the more general domain of $(a,b)$.\n",
    "\n",
    "We have several goals in this notebook.\n",
    "\n",
    "- Establish a unifying framework in which to define/analyze the continuous and discrete 2-point BVPs and their corresponding solutions. We utilize an operator notation to accomplish this in [Section 2.3.1](#Section2.3.1).\n",
    "\n",
    "- Analyze the shared properties of the differential and difference operators used in the definitions of the continuous and discrete problems. We define the properties we are interested in generally for an arbitrary operator acting on an inner product space and establish why they hold for both of the operators considered in this notebook in [Section 2.3.2](#Section2.3.2).\n",
    "\n",
    "- Analyze the shared properties of the continuous and discrete solutions. Important properties of the continuous solution are summarized in various theorems in [Section 2.1](Chp2Sec1.ipynb), and we discuss their discrete counterparts in [Section 2.3.3](#Section2.3.3) and [Section 2.3.4](#Section2.3.4).\n",
    "\n",
    "- Finally, we prove that the discrete solution *converges* to the continuous solution in [Section 2.3.5](#Section2.3.5).\n",
    "\n",
    "\n",
    "<mark>***This may require a few careful readings as there is a significant amount of theory discussed in this notebook. The material is unavoidably dense in places. It will likely take at least two classes to get through this all carefully.***</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2b5be8-fd6b-485f-a772-2e2f8133719a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just getting this out of the way\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cdd065-7471-4012-a722-3069df937d44",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='Section2.3.1'>Section 2.3.1: Operator Notation - A Useful Formalism</a>\n",
    "---\n",
    "\n",
    "To accomplish our goal, we find it convenient to rewrite the continuous and discrete problems with a new operator-centric notation. This also helps set the right mindset for how we approach modern PDE theory to study more general elliptic, parabolic, and hyperbolic PDEs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f14a441-5ceb-4c33-a3bc-2d751f00c1f9",
   "metadata": {},
   "source": [
    "---\n",
    "#### The continuous problem and its solution\n",
    "---\n",
    "\n",
    "We first rewrite the 2-point BVP\n",
    "\n",
    "$$\n",
    "    -u''(x) = f(x), \\ x\\in(0,1), \\ u(0)=u(1)=0,\n",
    "$$\n",
    "\n",
    "as\n",
    "\n",
    "$$\n",
    "    (Lu)(x) = f(x), \\ x\\in(0,1), \n",
    "$$\n",
    "\n",
    "where $L:\\mathcal{C}^2_0((0,1))\\to \\mathcal{C}((0,1))$ is the differential operator defined by $L:=-\\frac{d^2}{dx^2}$. \n",
    "\n",
    "- Here, $\\mathcal{C}^2_0((0,1))$ denotes the space $\\mathcal{C}^2((0,1))\\cap \\mathcal{C}([0,1])$ whose values at $x=0$ and $x=1$ are zero. \n",
    "\n",
    "  - In other words, $\\mathcal{C}^2_0((0,1))$ denotes the twice continuously differentiable functions on the *open interval* $(0,1)$ that are also continuous on the *closed* interval $[0,1]$ with values of $0$ at the endpoints. \n",
    "\n",
    "  - $\\mathcal{C}^2_0((0,1))$ is a vector subspace of the vector space $\\mathcal{C}^2((0,1))$.\n",
    "  \n",
    "  \n",
    "- It is worth emphasizing that just because a function has a value of zero at some point does not mean that its derivatives must be zero. Consider $u(x)=\\sin(\\pi x)$, which is zero at $x=0$ and $1$, but $u'(0)=\\pi$ and $u'(1)=-\\pi$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440aa7fa-b2aa-43af-840f-7ce2adaaba7f",
   "metadata": {},
   "source": [
    "**Remarks:**\n",
    "\n",
    "- For $u\\in\\mathcal{C}^2_0((0,1))$, we have that $Lu\\in\\mathcal{C}((0,1))$. If we start with a $u\\in\\mathcal{C}^2_0((0,1))$ and set $f=Lu\\in\\mathcal{C}((0,1))$, then we have *manufactured* a solution to the 2-point BVP that has this particular $f$ as the data.\n",
    "\n",
    "- <mark>The conceptual importance of the operator $L$ as a *mapping* from $u\\in\\mathcal{C}^2_0((0,1))$ to the *data* $f\\in\\mathcal{C}((0,1))$ cannot be overstated.</mark> It allows us to do things such as formally define the *solution operator* ``$L^{-1}:\\mathcal{C}((0,1))\\to\\mathcal{C}^2_0((0,1))$'' that maps the *data* to a *solution* of the BVP.\n",
    "\n",
    "Why are there quotes around ``$L^{-1}:\\mathcal{C}((0,1))\\to\\mathcal{C}^2_0((0,1))$'' in the above remark? We consider a linear algebra analogy which is also connected with what we discussed at the end of [Section 2.2](https://github.com/CU-Denver-MathStats-OER/Intro-PDEs-Theory-and-Computations/blob/main/Chp2/Chp2Sec2.ipynb) as well as in [Section 1.5](https://github.com/CU-Denver-MathStats-OER/Intro-PDEs-Theory-and-Computations/blob/main/Chp1/Chp1Sec5.ipynb) to set the proper mindset for how to interpret this notation.\n",
    "  \n",
    "We begin with the following problem: \n",
    "\n",
    "> Solve $Ax=b$ where $A\\in\\mathbb{R}^{m\\times n}$, $x\\in\\mathbb{R}^n$, and $b\\in\\mathbb{R}^m$.\n",
    "\n",
    "In this problem, $A:\\mathbb{R}^n\\to\\mathbb{R}^m$. \n",
    "\n",
    "*Question:* Does $A^{-1}:\\mathbb{R}^m\\to\\mathbb{R}^n$ always exist?\n",
    "\n",
    "- We can always evaluate $Ax$ for *any* given $x\\in\\mathbb{R}^n$, but does this mean that for *any* given $b\\in\\mathbb{R}^m$ that there exists $x\\in\\mathbb{R}^n$ such that $Ax=b$?\n",
    "\n",
    "  The answer is *of course **not***. Even if $m=n$, there are counterexamples. For example, consider the $2\\times 2$ matrix $A$ where each row is given by $(1, 0)$. $Ax=b$ only has solutions if $b=(b_1, 0)^\\top$ for some real number $b_1$. The vector $b=(0, 1)^\\top$ produces a problem with *no* solution because it is not in the column space of $A$.\n",
    "\n",
    "  Remember, *not every problem has a solution.*\n",
    "\n",
    "- But, suppose we have a $b\\in\\mathbb{R}^m$ such that there does exist an $x\\in\\mathbb{R}^n$ with $Ax=b$, then formally we may write $x=A^{-1}b$ even though $A^{-1}$ may not exist (e.g., perhaps $m\\neq n$ or if $m=n$ the rows of $A$ may be linearly dependent). \n",
    "\n",
    "  Moreover, even if $A^{-1}$ exists, the inverse of an invertible matrix is almost never constructed in practice! \n",
    "\n",
    "So, what are we really formally representing by writing $x=A^{-1}b$?\n",
    "\n",
    "- The symbol $A^{-1}$ often represents the *process* by which we determine the $x\\in\\mathbb{R}^n$ (perhaps that process is Gaussian elimination). \n",
    "\n",
    "Similarly, we may write $u=L^{-1}f$ by which we mean that we apply a more nuanced/sophisticated perspective to such notation.\n",
    "\n",
    "Of course, we have already established in the [Theorem of Existence,  Uniqueness, and Smoothness in Section 2.1](https://github.com/CU-Denver-MathStats-OER/Intro-PDEs-Theory-and-Computations/blob/main/Chp2/Chp2Sec1.ipynb) that for all $f\\in\\mathcal{C}((0,1))$ there exists a unique $u\\in\\mathcal{C}^2_0((0,1))$ such that $Lu=f$. But, if we were to change the boundary conditions (so consider an input space to the differential operator that was different than $\\mathcal{C}^2_0((0,1))$), this may not be the case.\n",
    "\n",
    "Moreover, just because the theorem implies the actual existence of an operator $L^{-1}:\\mathcal{C}((0,1))\\to\\mathcal{C}^2_0((0,1))$, it does *not* state what is fundamentally *meant* by writing $u=L^{-1}f$ because it is not stating *what* this operator $L^{-1}$ represents. \n",
    "\n",
    "What is it? In this case, we can think of it as the process by which we construct $u$ using the Green's function. In other words,\n",
    "\n",
    "$$\n",
    "    L^{-1}f = \\int_0^1 G(x,y)f(y)\\, dy.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83942dc-0b2b-4921-86d4-9c5ba78d58be",
   "metadata": {},
   "source": [
    "---\n",
    "#### The discrete problem and its solution\n",
    "---\n",
    "\n",
    "First, recall from the [previous notebook](https://github.com/CU-Denver-MathStats-OER/Intro-PDEs-Theory-and-Computations/blob/main/Chp2/Chp2Sec2.ipynb) that we use $n+2$ points to discretize $[0,1]$ into $n+1$ subintervals of equal length $h=1/(n+1)$ and we solve the matrix-vector problem\n",
    "\n",
    "\n",
    "$$\n",
    "\\large Av=b, \\ \\text{ where } \\ A = \\begin{pmatrix}\n",
    "                    2 & -1 & 0 & \\cdots & 0 \\\\\n",
    "                    -1 & 2 & -1 & \\ddots & \\vdots \\\\\n",
    "                    0 & \\ddots & \\ddots & \\ddots & 0 \\\\\n",
    "                    \\vdots & \\ddots & -1 & 2 & -1 \\\\\n",
    "                    0 & \\cdots & 0 & -1 & 2\n",
    "                \\end{pmatrix},\n",
    "            \\\n",
    "            \\\n",
    "             b = h^2\\begin{pmatrix}\n",
    "                        f(x_1) \\\\\n",
    "                        f(x_2) \\\\\n",
    "                        \\vdots \\\\\n",
    "                        f(x_n)\n",
    "                    \\end{pmatrix}, \n",
    "$$\n",
    "\n",
    "and $v\\in\\mathbb{R}^n$ represents $v=(v_1, v_2, \\ldots, v_n)^\\top\\approx (u(x_1), u(x_2), \\ldots, u(x_n))^\\top$.\n",
    "\n",
    "However, the above matrix-vector problem does not tell the whole story. The discrete problem includes boundary conditions. \n",
    "\n",
    "The *actual* vector $v$ that solves the discrete problem is in $\\mathbb{R}^{n+2}$ where $v_0=v_{n+1}=0$ and we solve for $v_1,v_2,\\ldots, v_n$ using the matrix-vector problem above because it is precisely this $(n+2)$-dimensional $v$ that satisfies the discrete problem that *includes* boundary conditions. \n",
    "\n",
    "This is an unfortunate abuse of notation. When we write $v$, how are we supposed to know if it is referring to the $n$-dimensional solution to the matrix-vector problem or the $(n+2)$-dimensional solution to the discrete problem? \n",
    "\n",
    "Well, the context helps. We solve the matrix-vector problem $Av=b$ to get the *unknown* values of $v$, and when we refer to $v$ by itself, we refer to the solution of the discrete problem which has dimension equal to the number of points used to discretize $[0,1]$.\n",
    "\n",
    "Note that if we change boundary conditions (e.g., making one or more unknown by the use of Neumann or Robin boundary conditions), then $A$ changes to reflect this (and belongs to either $\\mathbb{R}^{(n+1)\\times (n+1)}$ or $\\mathbb{R}^{(n+2)\\times (n+2)}$) as well as $b$ (and belongs to either $\\mathbb{R}^{n+1}$ or $\\mathbb{R}^{n+2}$) in order to solve for these additional unknown values in the $v\\in\\mathbb{R}^{n+2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1ad581-ed5a-4a50-ba36-6ad91d4b7d38",
   "metadata": {},
   "source": [
    "<mark>To help connect the discrete problem and its solution to the continuous problem and its solution, we need to take a step back to recall how $Av=b$ was even constructed and use a similar operator-based notation. However, we must first define the ***spaces*** that the operator will map between and their relationship to the continuous function spaces involved in the continuous problem.</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454da1c9-fd47-40d2-9d95-cb6ba28d69b5",
   "metadata": {},
   "source": [
    "---\n",
    "#### A Discrete Function Space\n",
    "---\n",
    "\n",
    "<mark>First, define $D_h$ as the collection of **discrete functions** that map the $n+2$ grid points $x_j=jh$, $0\\leq j\\leq n+1$ into $\\mathbb{R}$.</mark>\n",
    "\n",
    "- In other words, $w\\in D_h$ if $w(x_j)\\in\\mathbb{R}$ for each $0\\leq j\\leq n+1$. We will sometimes use $w_j$ as a shorthand notation for $w(x_j)$.\n",
    "\n",
    "- <mark>We are going to use $D_h$ to setup the solution spaces for the discrete problem.</mark>\n",
    "\n",
    "- *This is like a discrete version of $\\mathcal{C}^k([0,1])$ where we only consider functions whose values are defined at all the grid points in $D_h$ as opposed to being defined at all points in $[0,1]$ for $\\mathcal{C}^k([0,1])$.*  \n",
    "\n",
    "  Note that $\\mathcal{C}([0,1])\\subset D_h$ since if $w\\in\\mathcal{C}([0,1])$ then $w(x)\\in\\mathbb{R}$ for all $x\\in[0,1]$.\n",
    "  \n",
    "  However, $\\mathcal{C}((0,1))$ is not a subset of $D_h$ because functions like $1/x$ belong to $\\mathcal{C}((0,1))$ that are not defined as any real number for $x=0$.\n",
    "\n",
    "- We use the $\\sup$-norm metric to measure the distance between functions in $D_h$, i.e., we use the metric $d_{h,\\infty}:D_h\\times D_h\\to[0,\\infty)$ defined by\n",
    "  \n",
    "  $$\n",
    "      d_{h,\\infty}(v,w) := \\| v - w \\|_{h,\\infty} = \\sup_{0\\leq j\\leq n+1} | v_j - w_j |, \\ \\forall v, w\\in D_h.\n",
    "  $$\n",
    "  \n",
    "  Note that we used the $v_j, w_j$ shorthand notation above in-place of the function notation $v(x_j), w(x_j)$. Even though we use this shorthand notation, it is important to keep the perspective that $v$ and $w$ are in fact *functions* (discrete though they may be) defined on the grid points of $[0,1]$.\n",
    "  \n",
    "  When there is no chance for confusion (e.g., if we are only discussing the discrete functions), we may drop the $h$ in the subscript of the metric and norm.\n",
    "  \n",
    "- *Note that the metric space defined by $(D_h, d_{h,\\infty})$ is [isometrically isomorphic](https://en.wikipedia.org/wiki/Isometry) to $(\\mathbb{R}^{n+2}, d_\\infty)$. In other words, we can identify $D_h$ as $\\mathbb{R}^{n+2}$ equipped with the sup/infinity-norm induced metric.* \n",
    "\n",
    "  This means that even though we should always keep in mind that $D_h$ is a space of *functions*, we actually do not do anything mathematically incorrect if we happen to treat each function as the specific $(n+2)$-dimensional vector of real numbers defined by the function values at the grid points.\n",
    "  \n",
    "- *Of course, the function spaces we are dealing with are just vector spaces much like how the \"space of all polynomials up to degree $m$\" defines an $m$-dimensional vector space. The lesson here: linear algebra is a useful subject to study in depth.*\n",
    "\n",
    "  We therefore have that $D_h$ is \"obviously\" an $(n+2)$-dimensional vector space where as $\\mathcal{C}^k([0,1])$ is an infinite dimensional vector space.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50db8e1e-7b76-4eca-9bcb-8aa202f6b3bc",
   "metadata": {},
   "source": [
    " <mark>Second, define $D_{h,0}\\subset D_h$ as the *subset* of $D_h$ given by all $w\\in D_h$ such that $w_0=w_{n+1}=0$.</mark>\n",
    "\n",
    "- *It is a good exercise for students to show that this is in fact an $n$-dimensional vector subspace of $D_h$.*\n",
    "\n",
    "- $D_{h,0}$ will serve as the solution space to the discrete problem in an analogous way that $\\mathcal{C}^2_0((0,1))$ served as the solution space to the continuous problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca797436-6cb1-46d5-baf9-bc85ff60957e",
   "metadata": {},
   "source": [
    "<mark>Third, let $D_h^n$ denote the spaces of discrete functions similar to the above except that the superscript $n$ implies that we only consider the mapping of the $n$ interior grid points $x_j=jh$ for $1\\leq j\\leq n$ into $\\mathbb{R}$. </mark>\n",
    "\n",
    "- The use of the $n$ superscript should be interpreted similarly as the change from closed intervals $\\mathcal{C}([0,1])$ to open intervals in $\\mathcal{C}((0,1))$.\n",
    "\n",
    "  - Note that if $w\\in \\mathcal{C}([0,1])$, then $w\\in\\mathcal{C}((0,1))$. \n",
    "  \n",
    "    However, the converse is not necessarily true. For example, consider $w\\in\\mathcal{C}((0,1))$ defined by either $w(x)=1/x$ or $w(x)=\\sin(1/x)$. In either case, $\\lim_{x\\downarrow 0} w(x)$ does not exist implying there is no way to define $w(0)$ that makes $w$ continuous at $x=0$. \n",
    "    \n",
    "  - Similarly, if $w\\in D_h$, then $w\\in D_h^n$.\n",
    "  \n",
    "    The converse may not be true. However, it is no longer due to a lack of limits but rather the lack of a function value for a given $w\\in D_h^n$. For instance, $w(x)=1/x$ and $w(x)=\\sin(1/x)$ are simply *not defined* at $x=0$, so these $w$ are in $D_h^n$ but not in $D_h$.\n",
    "    \n",
    "    Of course, if we were to define $w$ in a piecewise manner, then we can get around certain issues like the above. For example, if $w(x)=1/x$ for $x>0$ but $w(0)=\\alpha$ (where $\\alpha\\in\\mathbb{R}$ is fixed), then $w\\in D_h$. \n",
    "    \n",
    "Why don't we similarly define $D_{h,0}^n$? Well, $D_{h,0}^n$ is equivalent to $D_{h,0}$, so there is really no point in doing so. It is just a manner of semantics. Writing $\\mathcal{C}_0((0,1))$ and $\\mathcal{C}_0([0,1])$ also mean the same thing, but we never write the latter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031f3ed8-8e5d-41ab-9800-1bdd55e716a1",
   "metadata": {},
   "source": [
    "<mark>Fourth, define the *difference operator* $L_h: D_{h,0} \\to D_{h}^n$ given by</mark>\n",
    "\n",
    "\n",
    "$$\n",
    "    (L_hw)(x_j) = - \\frac{w(x_{j+1}) - 2w(x_j) + w(x_{j-1})}{h^2}, \\ \\text{ for } 1\\leq j \\leq n. \n",
    "$$\n",
    "\n",
    "- Note that $L_hw \\in D_h^n$, i.e., $L_h$ is an operator that maps a discrete function $w\\in D_{h,0}^n$ and creates a new discrete function $L_hw\\in D_h^n$. \n",
    "\n",
    "- We are not making any statement/claim as to whether or not $L_hw\\in D_h$. \n",
    "\n",
    "- We can apply $L_h$ to any $w\\in\\mathcal{C}_0((0,1))$. In particular, if $w\\in \\mathcal{C}^2_0((0,1))$, then we identify the function $L_hw\\in D_h^n$ as the function that approximates $w''$ at the interior grid points $x_j=jh$ for $1\\leq j\\leq n$, i.e., $L_hw(x_j)\\approx w''(x_j)$ for each $1\\leq j \\leq n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b74e0e-1a69-4e35-8466-0f360a9255d5",
   "metadata": {},
   "source": [
    "<mark>Fifth, define the **discrete problem in operator form** as finding $v\\in D_{h,0}$ such that</mark>\n",
    "\n",
    "$$\n",
    "    (L_hv)(x_j) = f(x_j), \\ 1\\leq j\\leq n.\n",
    "$$\n",
    "\n",
    "We now have the discrete problem in a form analogous to the form given in the continuous problem: $(Lu)(x)=f(x)$ for all $x\\in (0,1)$. \n",
    "\n",
    "- A key observation is that $L:\\mathcal{C}^2_0((0,1))\\to\\mathcal{C}((0,1))$ is replaced by $L_h:D_{h,0}\\to D_h^n$.\n",
    "\n",
    "- Note that we are writing the discrete problem as a system of $n$ equations in this form, and the matrix-vector problem $Av=b$ where we define $v_0=v_{n+1}=0$ is an equivalent way to represent this problem as a single equation (a single equation involving a matrix and a vector)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64653c8c-fb7b-4c32-843c-333985e02ed0",
   "metadata": {},
   "source": [
    "<mark>Finally, make sense of what $v=L_h^{-1}f$ means for $f\\in D_h^n$.</mark>\n",
    "\n",
    "As discussed at the end of the previous notebook, $v=A^{-1}b$ because $A$ is a symmetric positive definite matrix, so it is invertible. \n",
    "\n",
    "Thus, we can determine $v_1, \\ldots, v_n$ via the coordinates of the vector $A^{-1}b$ (and we may interpret $A^{-1}$ as the process of applying Gaussian elimination), and we can interpret $v = L_h^{-1}f$ as simply meaning:\n",
    "\n",
    "$$\n",
    "    L_h^{-1}f(x_j) = \\begin{cases}\n",
    "                        (A^{-1}b)_j, & \\text{ if } 1\\leq j\\leq n, \\\\\n",
    "                        0, & \\text{ if } j\\in{0,n+1}.\n",
    "                     \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720e56a8-a40a-4801-897b-b6c6620a847a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We make sense of $L_h^{-1}f$ below for solving the discrete problem by\n",
    "# revisiting code from the previous notebook\n",
    "\n",
    "def make_A(n):\n",
    "    A = np.zeros((n,n))\n",
    "    np.fill_diagonal(A,2)\n",
    "    A += np.diag(-np.ones(n-1),k=1)\n",
    "    A += np.diag(-np.ones(n-1),k=-1)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57523a1a-01f4-4bed-a8a9-d5594787067f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_Av_b(n, f):  # This is saying \"Construct $L_h^{-1}f$\"\"\n",
    "    \n",
    "    A = make_A(n)  # Construct $A$\n",
    "    \n",
    "    x = np.linspace(0, 1, n+2)  # Create the n+2 grid points\n",
    "    h = x[1]-x[0]  # Determine h=1/(n+1), which is also just the difference between grid points\n",
    "    b = h**2*f(x[1:-1])  # Construct $b$\n",
    "    \n",
    "    # Note that v is a n+2 dimensional vector that is storing what we mean by $L_h^{-1}f$\n",
    "    v = np.zeros(n+2)  \n",
    "    \n",
    "    # Below, we compute \"$A^{-1}b$\" for $1\\leq j\\leq n$. The 0's at j=0 and j=n+1 are untouched \n",
    "    # We use quotes around $A^{-1}b$ because we use the solve method in numpy's linalg subpackage,\n",
    "    # which is utilizing routines for solving matrix-vector problems without constructing the inverse\n",
    "    # of the matrix A.\n",
    "    v[1:-1] = np.linalg.solve(A, b)  \n",
    "    \n",
    "    return v, x, h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb170b23-a44d-46d2-b0af-5c0fba7750c7",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='Section2.3.2'>Section 2.3.2: Properties of $L$ and $L_h$</a>\n",
    "---\n",
    "\n",
    "First, we define inner products  $\\langle \\cdot, \\cdot \\rangle$ and  $\\langle \\cdot, \\cdot \\rangle_h$ on $\\mathcal{C}([0,1])$ and $D_h$, respectively, as\n",
    "\n",
    "$$\n",
    "    \\langle u, v \\rangle := \\int_0^1 u(x)v(x)\\, dx, \\ \\forall \\ u, v\\in\\mathcal{C}([0,1]), \n",
    "$$\n",
    "\n",
    "and, by applying the [trapezoidal rule](https://en.wikipedia.org/wiki/Trapezoidal_rule) on each of the $n+1$ subintervals of length $h$ used to discrete $[0,1]$ to approximate this integral, we define\n",
    "\n",
    "$$\n",
    "    \\langle u, v \\rangle_h := h\\left[\\frac{u_0v_0+u_{n+1}v_{n+1}}{2} + \\sum_{j=1}^n u_jv_j\\right].\n",
    "$$\n",
    "\n",
    "**Remarks:**\n",
    "\n",
    "- We call $\\langle \\cdot, \\cdot \\rangle$ the **continuous inner product** and $\\langle \\cdot, \\cdot \\rangle_h$ the **discrete inner product.**\n",
    "\n",
    "- Inner products impart a *geometric structure* on a space (as well as a norm, metric, topology, etc.). \n",
    "\n",
    "  - Since the discrete inner product is developed as an approximation of the continuous inner product, this suggests that the structures/analysis on either space should be approximately mirrored by the other space.\n",
    "  \n",
    "  - We in fact witness this \"mirrored\" analysis throughout the rest of this chapter where steps in analyzing properties of $L_h$ and solutions to the discrete problem in $D_{h,0}$ \"mirror\" the steps in analyzing properties of $L$ and solutions to the continuous problem in $\\mathcal{C}^2_0((0,1))$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee63d4de-d1ba-4847-a5dd-3b4c22790fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import quadrature as quad\n",
    "\n",
    "def inner(u, v):\n",
    "    z = quad(lambda x: u(x)*v(x), 0, 1)[0]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74915040-2d5c-4967-a2ed-b3b2f21c82b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_h(u, v, h):\n",
    "    z = h * (u[0]*v[0] + u[-1]*v[-1])/2.0 + h*np.dot(u[1:-1],v[1:-1])\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0affeab-b9c1-4a44-9683-8a6e99ff231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compare these inner products on some continuous functions on [0,1].\n",
    "# They should give similar answers if enough grid points are used.\n",
    "# What is enough? Well, it depends on the functions.\n",
    "\n",
    "u = lambda x : np.sin(x)\n",
    "v = lambda x : np.exp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e193d4b2-53ff-4bde-9351-d55d4be7e41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-'*70)\n",
    "print('The continuous inner product of u and v is\\n')\n",
    "print(inner(u, v))\n",
    "print()\n",
    "\n",
    "n = 19\n",
    "x = np.linspace(0, 1, n+2)\n",
    "h = x[1]-x[0]\n",
    "print('-'*70)\n",
    "print('The discrete inner product of u and v using ' + str(n+2) + ' grid points is\\n')\n",
    "print(inner_h(u(x), v(x), h))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d16a56-e8c1-43d7-aba8-dd15b9e46994",
   "metadata": {},
   "source": [
    "---\n",
    "#### How good of an approximation is the discrete inner product to the continuous inner product?\n",
    "---\n",
    "\n",
    "Here, we explore the quality of the approximation of the continuous inner product by the discrete inner product. \n",
    "\n",
    "First, we prove that if $u,v\\in C_0^2((0,1))$ then \n",
    "$$\n",
    "\\large    \\left| \\left< u, v \\right> -  \\left< u, v \\right>_h \\right| \\leq \\frac{h^2}{12} \\left|\\left| (uv)'' \\right|\\right|_\\infty\n",
    "$$\n",
    "\n",
    "In the proof below, we use the well established [error bound](https://en.wikipedia.org/wiki/Trapezoidal_rule#Error_analysis) associated with the [Trapezoidal rule](https://en.wikipedia.org/wiki/Trapezoidal_rule).\n",
    "\n",
    "***Proof:***\n",
    "\n",
    "Let $u,v\\in C_0^2((0,1))$. \n",
    "Then, $uv\\in C_0^2((0,1))$.\n",
    "\n",
    "Let $f=uv$. \n",
    "Then, $\\int_0^1 f(x)\\, dx = \\left<u,v\\right>$ and $\\left<u,v\\right>_h$ is identified as the trapezoidal rule applied to this integral.\n",
    "The result follows immediately from the established error bound for the trapezoidal rule. $\\Box$\n",
    "\n",
    "***Some extra material***\n",
    "\n",
    "If you've never seen the proof of the error bound for the trapezoidal rule, it follows from applying the [integration by parts](https://en.wikipedia.org/wiki/Integration_by_parts) formula with some creative choices of integration constants.\n",
    "We sketch out the process as a two-step process below that you may find more useful than the Wiki reference linked to above.\n",
    "This also helps set the stage for some of the techniques used to prove other results in this notebook.\n",
    "\n",
    "**A useful Lemma:** For $f\\in C^2((0,1))$, let $x_i\\in[0,1)$ and $h>0$ sufficiently small so that $x_i+h\\in[0,1]$\n",
    "\n",
    "$$\n",
    "    \\left|\\int_{x_i}^{x_i+h} f(x)\\, dx - \\frac{h}{2}(f(x_i+h)-f(x_i)) \\right| \\leq \\frac{h^3}{12}\\left|\\left|  f''\\right|\\right|_\\infty.\n",
    "$$\n",
    "\n",
    "**Sketch of Proof:** A simple change of variables (to simplify the limits of integration) followed by integrating by parts twice with clever choices of integration constants leads to\n",
    "\n",
    "$$\n",
    "    \\int_{x_i}^{x_i+h} f(x)\\, dx = \\int_0^h f(t+x_i)\\, dt = \\underbrace{\\frac{h}{2}\\left[f(x_i) + f(x_i+h)\\right]}_{\\text{Trap. Rule}} + \\underbrace{\\int_{0}^{h} \\left(\\frac{(t-h/2)^2}{2}-\\frac{h^2}{8} \\right)f''(t+x_i)\\, dt}_{\\text{Error in Trap. Rule on $(x_i, x_i+h)$}}.\n",
    "$$\n",
    "\n",
    "So it follows that the error can be bounded by\n",
    "\n",
    "$$\n",
    "    \\left| \\int_{0}^{h} \\left(\\frac{(t-h/2)^2}{2}-\\frac{h^2}{8} \\right)f''(t+x_i)\\, dt \\right| \\leq \\left|\\left|f''\\right|\\right|_\\infty \\int_0^h \\left| \\frac{(t-h/2)^2}{2}-\\frac{h^2}{8} \\right| \\, dt. \n",
    "$$\n",
    "\n",
    "The integrand is the absolute value of a parabola $\\displaystyle \\frac{(t-h/2)^2}{2}-\\frac{h^2}{8}$ which opens upward and is zero whenever $t-h/2 = \\pm h/2$ (i.e., at $t=0$ and at $t=h$), so for $t\\in(0,h)$, we have that\n",
    "\n",
    "$$\n",
    "    \\left|\\frac{(t-h/2)^2}{2}-\\frac{h^2}{8}\\right| = \\frac{h^2}{8} - \\frac{(t-h/2)^2}{2}. \n",
    "$$\n",
    "\n",
    "It follows from a direct integration of this term that the error in the trapezoidal rule on $(x_i,x_i+h)$ is bounded by\n",
    "\n",
    "$$\n",
    "    \\left| \\int_{0}^{h} \\left(\\frac{(t-h/2)^2}{2}-\\frac{h^2}{8} \\right)f''(t+x_i)\\, dt \\right| \\leq \\frac{h^3}{12}\\left|\\left|f''\\right|\\right|_\\infty.\n",
    "$$\n",
    "\n",
    "Since we apply the trapezoidal rule on $n$ subintervals, we add up the error bound $n$ times and use the fact that $h=1/n$ to get the result used in the proof above. $\\Box$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ccffd0-ec50-4361-8b02-29df4e49f9bb",
   "metadata": {},
   "source": [
    "---\n",
    "#### Symmetry of operators\n",
    "---\n",
    "\n",
    "<mark>For an operator $\\mathcal{L}$ on a real-valued vector space equipped with an inner product (with inner product denoted by $\\langle \\cdot, \\cdot \\rangle$) to be symmetric, it means that $\\langle \\mathcal{L}u, v\\rangle = \\langle u, \\mathcal{L}v\\rangle$ for all $u$ and $v$ in the space.</mark>\n",
    "\n",
    "Using [integration by parts](https://en.wikipedia.org/wiki/Integration_by_parts) twice, we can prove (details are left to the students or will be covered in class) that $L$ is **symmetric** meaning that\n",
    "\n",
    "$$\n",
    "    \\langle Lu, v \\rangle = \\langle u, Lv\\rangle, \\ \\forall \\ u, v\\in\\mathcal{C}_0^2((0,1)).\n",
    "$$\n",
    "\n",
    "Similarly, using [summation by parts](https://en.wikipedia.org/wiki/Summation_by_parts) twice (and by defining $u_{-1}=v_{-1}=0$ to simplify notation), we can prove (details are left to the students or will be covered in class) that $L_h$ is **symmetric** meaning that \n",
    "\n",
    "$$\n",
    "    \\langle L_hu, v \\rangle_h = \\langle u, L_hv\\rangle_h, \\ \\forall \\ u, v\\in D_{h,0}.\n",
    "$$\n",
    "\n",
    "We summarize these results in the following Lemma for ease of reference.\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "#### Lemma 2.3.1: Symmetry of Operators\n",
    "\n",
    "The operators $L$ and $L_h$ are symmetric in the sense given above.\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47e4beb-9563-47d3-8123-e21c702af659",
   "metadata": {},
   "source": [
    "<mark>**Note that \"in the sense given above\" makes *explicit* mention of the spaces of functions for which this symmetry holds. If either function (or both) fail to be in these spaces, then symmetry does not necessarily hold. We explore this below.**</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c34fb3-ce5f-41d2-b9ed-2d6900df6ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sp\n",
    "from sympy.utilities.lambdify import lambdify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a0cc66-4264-45c0-89c8-8bbc3649f94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L(u):\n",
    "    return -u.diff(x,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2951857-4348-4789-ad1c-6606e4695773",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = sp.symbols('x')\n",
    "\n",
    "# The following u, v FAIL to be in the correct spaces for symmetry to necessarily hold.\n",
    "u = sp.sin(x)  \n",
    "v = sp.exp(x)\n",
    "\n",
    "Lu = L(u)\n",
    "Lv = L(v)\n",
    "\n",
    "u_eval = lambdify(x, u)\n",
    "v_eval = lambdify(x, v)\n",
    "\n",
    "Lu_eval = lambdify(x, Lu)\n",
    "Lv_eval = lambdify(x, Lv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89b2ead-8294-4a3d-a7c4-74b822d20cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-'*70)\n",
    "print('The continuous inner product of Lu and v is\\n')\n",
    "print(inner(Lu_eval, v_eval))\n",
    "print()\n",
    "print('The continuous inner product of u and Lv is\\n')\n",
    "print(inner(u_eval, Lv_eval))\n",
    "print()\n",
    "\n",
    "n = 19\n",
    "x = np.linspace(0, 1, n+2)\n",
    "h = x[1]-x[0]\n",
    "print('-'*70)\n",
    "print('The discrete inner product of Lu and v using ' + str(n+2) + ' grid points is\\n')\n",
    "print(inner_h(Lu_eval(x), v_eval(x), h))\n",
    "print()\n",
    "print('The discrete inner product of u and Lv using ' + str(n+2) + ' grid points is\\n')\n",
    "print(inner_h(u_eval(x), Lv_eval(x), h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a0ec1e-5bd5-42a1-a997-55c4042f6a79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = sp.symbols('x')\n",
    "\n",
    "# The following u, v are designed to be in the correct spaces for symmetry to hold.\n",
    "# By \"designed\", we mean that we subtract the straight line connecting the end-point\n",
    "# values in order to ensure that u(0)=v(0)=0 and u(1)=v(1)=0.\n",
    "u = sp.sin(x) - (sp.sin(0)*(1-x)+sp.sin(1)*x) \n",
    "v = sp.exp(x) - (sp.exp(0)*(1-x)+sp.exp(1)*x)\n",
    "\n",
    "Lu = L(u)\n",
    "Lv = L(v)\n",
    "\n",
    "u_eval = lambdify(x, u)\n",
    "v_eval = lambdify(x, v)\n",
    "\n",
    "Lu_eval = lambdify(x, Lu)\n",
    "Lv_eval = lambdify(x, Lv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cd7e7e-cf41-4f0f-b975-fdede2305d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-'*70)\n",
    "print('The continuous inner product of Lu and v is\\n')\n",
    "print(inner(Lu_eval, v_eval))\n",
    "print()\n",
    "print('The continuous inner product of u and Lv is\\n')\n",
    "print(inner(u_eval, Lv_eval))\n",
    "print()\n",
    "\n",
    "n = 19\n",
    "x = np.linspace(0, 1, n+2)\n",
    "h = x[1]-x[0]\n",
    "print('-'*70)\n",
    "print('The discrete inner product of Lu and v using ' + str(n+2) + ' grid points is\\n')\n",
    "print(inner_h(Lu_eval(x), v_eval(x), h))\n",
    "print()\n",
    "print('The discrete inner product of u and Lv using ' + str(n+2) + ' grid points is\\n')\n",
    "print(inner_h(u_eval(x), Lv_eval(x), h))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff815c1a-8b45-414f-a915-2238add641bb",
   "metadata": {},
   "source": [
    "---\n",
    "#### Positive definiteness of operators\n",
    "---\n",
    "\n",
    "<mark>For an operator $\\mathcal{L}$ on a vector space equipped with an inner product (with inner product denoted by $\\langle \\cdot, \\cdot \\rangle$) to be positive definite, it means that $\\langle \\mathcal{L}u, u\\rangle\\geq 0$ for all $u$ in the space with equality only happening if $u$ is equivalent to the zero vector.</mark>\n",
    "\n",
    "By applying integration by parts once, we have that for any $u\\in\\mathcal{C}_0^2((0,1))$\n",
    "\n",
    "$$\n",
    "    \\langle Lu, u \\rangle = \\int_0^1 (u'(x))^2\\, dx.\n",
    "$$\n",
    "\n",
    "Since the above integral involves a nonnegative function (because we are squaring $u'(x)$), the integral is nonnegative. This implies $\\langle Lu, u \\rangle\\geq 0$ with equality only if $u(x)\\equiv 0$.. \n",
    "\n",
    "Moreover, for continuous nonnegative functions, the integral is zero if and only the integrand is identically zero, i.e., $(u'(x))^2\\equiv 0$ on $[0,1]$, which is equivalent to saying that $u'(x)\\equiv 0$ on $[0,1]$. \n",
    "\n",
    "If a derivative is constant on an interval, then the function is constant. Thus, if $u'(x)\\equiv 0$ on $[0,1]$, then $u(x)=c$ for some $c\\in\\mathbb{R}$ on $[0,1]$. But, since we started with $u\\in\\mathcal{C}_0^2((0,1))$, we know that $u(0)=u(1)=0$, which means that $c=0$. \n",
    "\n",
    "Therefore, $\\langle Lu, u \\rangle\\geq 0$ with equality only if $u(x)\\equiv 0$.\n",
    "\n",
    "Similarly, for any $v\\in D_{h,0}$, we can apply summation by parts once (again using the convenient definition of $v_{-1}=0$ to make this step more obvious) and group terms to get\n",
    "\n",
    "$$\n",
    "    \\langle L_h v, v\\rangle_h = h^{-1}\\sum_{j=0}^n (v_{j+1}-v_j)^2.\n",
    "$$\n",
    "\n",
    "Since the above summation involves nonnegative terms (again, they are squared), we have that the sum is greater than or equal to zero. \n",
    "\n",
    "Moreover, if the sum is zero, then this can only happen if $v_{j+1}=v_j$ for all $0\\leq j\\leq n$. Since $v\\in D_{h,0}$ implies $v_0=0$, this further implies $v_j=0$ for $0\\leq j\\leq n+1$. In other words, $v$ is equivalent to the discrete function that is identically zero.\n",
    "\n",
    "\n",
    "We summarize these results in the following Lemma for ease of reference.\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "#### Lemma 2.3.2: Positive Defineteness of Operators\n",
    "\n",
    "The operators $L$ and $L_h$ are positive definite in the sense given above.\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f113a8fc-0c35-412f-8294-ed5759eaa1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inner(Lu_eval, u_eval))\n",
    "print(inner(Lv_eval, v_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867b0dce-d50e-436f-a227-099962d9481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 19\n",
    "x = np.linspace(0, 1, n+2)\n",
    "h = x[1]-x[0]\n",
    "\n",
    "print(inner_h(Lu_eval(x), u_eval(x), h))\n",
    "print(inner_h(Lv_eval(x), v_eval(x), h))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6537dc48-f94f-4e44-866d-d84e1cf31237",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='Section2.3.3'>Section 2.3.3: Existence and Uniqueness of Continuous and Discrete Solutions</a>\n",
    "---\n",
    "\n",
    "<mark>Consider a *linear* positive definite operator $\\mathcal{L}:W\\subset V\\to V$ where $V$ is a vector space equipped with an inner product (with inner product denoted by $\\langle \\cdot, \\cdot \\rangle$) and $W$ is some vector subspace of $V$. If the problem defined by $\\mathcal{L}w=v$ has a solution, then the solution is unique.</mark>\n",
    "\n",
    "To see that the above statement is true, suppose $w_1$ and $w_2$ are both solutions to the same problem $\\mathcal{L}w=v$. Define $e=w_1-w_2$. Then, by linearity of $\\mathcal{L}$, we have that\n",
    "\n",
    "$$\n",
    "    \\mathcal{L}e = \\mathcal{L}(w_1-w_2) = \\mathcal{L}w_1-\\mathcal{L}w_2 = v-v=0\\in V.\n",
    "$$\n",
    "\n",
    "Since the inner product with the zero vector always produces zero, this implies that \n",
    "\n",
    "$$\n",
    "    \\langle \\mathcal{L}e, e\\rangle = \\langle 0, e \\rangle = 0.\n",
    "$$\n",
    "\n",
    "Recalling that $\\mathcal{L}$ is positive definite, we have that this implies $e$ is the zero vector in $V$.\n",
    "\n",
    "Since we have previously argued that solutions exist to the continuous and discrete problems (i.e., $u=L^{-1}f$ and $v=L_h^{-1}f$ both exist), and both $L$ and $L_h$ are positive definite, we have that the continuous and discrete solutions are unique. We summarize this as\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "#### Lemma 2.3.3: Existence and Uniqueness of Solutions\n",
    "\n",
    "The functions $u=L^{-1}f\\in\\mathcal{C}_0^2((0,1))$ and $v=L_h^{-1}f\\in D_{h,0}$ defined above in Section 2.3.1 are the unique solutions to the continuous and discrete problems, respectively.\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd03d89-2e70-458e-8305-4de7352b62a0",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='Section2.3.4'>Section 2.3.4: Maximum Principle and Monotonicity for Continuous and Discrete Solutions</a>\n",
    "---\n",
    "\n",
    "Recall that on both $\\mathcal{C}^2_0((0,1))$ and $D_{h,0}$ that we use the sup-norm (i.e., infinity-norm) induced metric (not the norm or metric induced by the inner products discussed above).\n",
    "\n",
    "Recall from [Section 2.1](https://github.com/CU-Denver-MathStats-OER/Intro-PDEs-Theory-and-Computations/blob/main/Chp2/Chp2Sec1.ipynb) the following\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "**Theorem 2.1.3: Maximum principle**\n",
    "\n",
    "Assume that $f\\in\\mathcal{C}((a,b))$ and let $u$ be the unique solution of the BVP given in Theorem 2.1.1, then\n",
    "\n",
    "$$\n",
    "    \\| u \\|_\\infty \\leq \\frac{(b-a)^2}{8}\\|f\\|_\\infty.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "In the simplified case of this notebook where $a=0$ and $b=1$, the result in this theorem simplifies to\n",
    "\n",
    "$$\n",
    "    \\| u \\|_\\infty \\leq \\frac{1}{8}\\|f\\|_\\infty\n",
    "$$\n",
    "\n",
    "We similarly have (notice the mirroring in the numbering of this theorem which occurred entirely by accident)\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "**Theorem 2.3.1: Maximum principle**\n",
    "\n",
    "Assume that $f\\in\\mathcal{C}((0,1))$ and let $v\\in D_{h,0}$ be the unique solution of the discrete version of the BVP considered in this notebook, then \n",
    "\n",
    "$$\n",
    "    \\| v \\|_{h,\\infty} \\leq \\frac{1}{8}\\|f\\|_{h,\\infty}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "**Remark:**\n",
    "\n",
    "- Note that the linear interpolant of any function in $D_{h}$ defines a function in $\\mathcal{C}((0,1))$, so the above result can be modified to hold for any $f\\in D_{h}$ as well.\n",
    "\n",
    "**Outline of proof for Theorem 2.3.1:**\n",
    "\n",
    "1. For each $1\\leq k\\leq n$, verify that $G^k(\\cdot) := G(\\cdot, x_k) \\in D_{h,0}$ (where $G$ is the Green's function associated with the continuous problem) solves the discrete problem with a forcing function $\\frac{1}{h}e^k$ chosen so that \n",
    "\n",
    "$$\n",
    "    e^k(x_j) := \\begin{cases}\n",
    "                              1, & k=j, \\\\\n",
    "                              0, & \\text{else}.\n",
    "                          \\end{cases}\n",
    "$$\n",
    "\n",
    "2. Use this to verify that a solution $w\\in D_{h,0}$ for an arbitrary $f\\in D_{h,0}$ can be written as\n",
    "<br>\n",
    "$$\n",
    "    w(x_j) := h \\sum_{k=1}^n f(x_k) G^k(x_j), \n",
    "$$\n",
    "\n",
    "   by observing first that $f(\\cdot) = \\sum_{k=1}^n f(x_k)e^k(\\cdot)$.\n",
    "\n",
    "\n",
    "3. Recognize that if $f$ is defined as a constant function, i.e., $f(x)\\equiv \\alpha$, then \n",
    "\n",
    "   $$\n",
    "       w(x_j) = \\alpha h\\sum_{k=1}^n G^k(x_j), \n",
    "   $$\n",
    "\n",
    "   and show that this is equivalently written as\n",
    "   \n",
    "   $$\n",
    "       w(x_j) = \\alpha \\frac{1}{2} x_j(1-x_j)\n",
    "   $$\n",
    "\n",
    "4. Use the fact that $\\frac{1}{2}x(1-x)$ is bounded by $\\frac{1}{8}$ for all $x\\in[0,1]$ and that $\\|f\\|_{h,\\infty}$ is \"just some $\\alpha\\in[0,\\infty)$\" to arrive at the desired conclusion.\n",
    "\n",
    "**Motivation for the first step in the proof:**\n",
    "\n",
    "How would one ever conceive of this first step? There are a few ideas that can nudge us in this direction.\n",
    "\n",
    "First, the Green's function was key to proving Theorem 2.1.3.\n",
    "\n",
    "Second, it is always a good idea to see \"plug\" an exact solution to a continuous problem into the discrete problem to build intuition for discretization errors. \n",
    "\n",
    "The Green's function, $G(x,y)$, to the continuous problem is essentially the solution to the continuous problem when $f(x)=\\delta(x-y)$. It is perhaps not too surprising then that for a fixed $y=x_k$, $G(\\cdot, x_k)$ defines a function in $D_{h,0}$ that solves the discrete problem associated with a forcing function that is non-zero only at the grid point $x_k$. \n",
    "\n",
    "In fact, we refer to the $G^k(\\cdot)=G(\\cdot, x_k)$ as the **discrete Green's functions.**\n",
    "\n",
    "<mark>Filling in all the details of the proof are left for either the students or in-class presentation.</mark>\n",
    "\n",
    "Utilizing both Step 2 in the proof of Theorem 2.3.1 and the fact that $G(x,y)\\geq 0$ for all $x,y\\in[0,1]$ implies $G^k(x_j)\\geq 0$ for all grid points $x_j$ allows us to immediately prove the following monotonicity result that mirrors Theorem 2.1.2 from  [Section 2.1](https://github.com/CU-Denver-MathStats-OER/Intro-PDEs-Theory-and-Computations/blob/main/Chp2/Chp2Sec1.ipynb) that we write as Theorem 2.3.2 below.\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "**Theorem 2.3.2: Monotonicity**\n",
    "\n",
    "Assume that $f\\in\\mathcal{C}((0, 1))$ is a nonnegative function, and let $v\\in D_{h,0}$ be the unique solution of the discrete version of the BVP considered in this notebook, then $v(x_j)\\geq 0$ for $1\\leq j\\leq n$.\n",
    "\n",
    "---\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ad847f-5628-4fdd-a1fc-d80ed7c75cb0",
   "metadata": {},
   "source": [
    "**A slightly deeper dive into the discrete Green's function**\n",
    "\n",
    "- One take home message is that the discrete analog of the Dirac delta function is given by $\\frac{1}{h} e^k$ where $e^k\\in D_{h,0}$ is defined by $e^k(x_k)=1$ and $e^k(x_j)=0$ if $j\\neq k$.\n",
    "\n",
    "- Observe that we required that $1\\leq k\\leq n$, i.e., we evaluate at an interior point since $e^k\\in D_{h,0}$ automatically implies that $e^k(x_0)=0=e^k(x_{n+1})$.\n",
    "\n",
    "- It is just worth emphasizing again that the discrete Green's function is given by $G^k(x_j) = G(x_j,x_k)$ where $G$ is the Green's function for the continuous problem and we have that $L_h G^k = \\frac{1}{h}e^k$. \n",
    "\n",
    "If we were to construct the discrete Green's function, we would store it as a $\\mathbb{R}^{(n+2)\\times (n+2)}$ matrix as we show below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8d1be2-3c94-4a3b-a57f-37c6ccf88b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def G(x,y): \n",
    "    if 0 <= y <= x:\n",
    "        z = y*(1-x)\n",
    "    else:\n",
    "        z = x*(1-y)\n",
    "    return z\n",
    "\n",
    "def make_G(n, x):    \n",
    "    G_k = np.zeros((n+2,n+2))\n",
    "    for j in range(0,n+2):\n",
    "        for k in range(0,n+2):\n",
    "            G_k[j,k] = G(x[j],x[k])\n",
    "    return G_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b992a6-8c32-4d70-8650-670c7c33eafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "\n",
    "x = np.linspace(0,1,n+2)\n",
    "h = x[1]-x[0]  # So 1/h = n+1\n",
    "\n",
    "G_k = make_G(n,x)\n",
    "        \n",
    "A = make_A(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4b39b3-2214-41e2-b0cd-2bd12ea2b5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an integer between 0 and n+1\n",
    "k = 2\n",
    "\n",
    "test = np.zeros(n+2)\n",
    "test[1:-1] = 1/h**2 * np.dot(A,G_k[1:-1,k])  # This should produce the e^k function\n",
    "\n",
    "%matplotlib widget\n",
    "plt.figure(0) \n",
    "plt.plot(x,test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba8e9cc-69a4-4352-b43d-b8c0ea683a6f",
   "metadata": {},
   "source": [
    "With the inner product notation, we have for the continuous problem $u(x) = \\left< G(x,y),f(y) \\right>$ (where the integral is with respect to $y$ not $x$), and now for the discrete problem we also have that $v(x_j) = \\left< G^k(x_j), f \\right>_h$ (where the summation is with repect to $k$ not $j$).\n",
    "\n",
    "This implies another way for construction solutions, which we explore numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d25e0a-d8e3-48df-bd72-a7cdec7f6480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way to construct solutions\n",
    "\n",
    "# First, the old way of constructing solutions\n",
    "b_old = h**2 * (3*x+x**2)*np.exp(x)  # So, f is (3x+x^2)e^x\n",
    "\n",
    "v_old = np.zeros(n+2)\n",
    "v_old[1:-1] = np.linalg.solve(A, b_old[1:-1])  # Numerical soln. using Gaussian elimination\n",
    "\n",
    "# Now, the new one\n",
    "b_new = (3*x+x**2)*np.exp(x)\n",
    "\n",
    "v_new = np.zeros(n+2)\n",
    "for j in range(1,n+1):\n",
    "    v_new[j] += inner_h(G_k[j,:], b_new, h)\n",
    "\n",
    "u = x*(1-x)*np.exp(x)  # Exact soln.\n",
    "\n",
    "# Let's compare the approaches\n",
    "%matplotlib widget\n",
    "plt.figure(1)\n",
    "plt.plot(x, v_new, 'g--', label='Num. Soln. $v_{new}$')\n",
    "plt.plot(x, v_old, 'b.', markersize=15, label='Num. Soln. $v_{old}$')\n",
    "plt.legend(loc='upper left', shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43cedb6-59d2-4621-8762-dbf201e6bdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking that the maximum principle holds\n",
    "\n",
    "ns = range(1,30)\n",
    "\n",
    "for n in ns:\n",
    "    x = np.linspace(0,1,n+2)\n",
    "    h = x[1]-x[0]  # So 1/h = n+1\n",
    "\n",
    "    G_k = make_G(n, x)\n",
    "    \n",
    "    temp = np.zeros(n+2)\n",
    "    for i in range(0,n+2):\n",
    "        temp[i] = inner_h(G_k[:,i], np.ones(n+2), h)  # Choosing f\\equiv 1, so the max value should be $\\leq$ 1/8\n",
    "        \n",
    "    print(np.max(temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e224256d-5309-42d7-88d9-90c89e984eeb",
   "metadata": {},
   "source": [
    "---\n",
    "#### A word of caution about discrete Green's functions.\n",
    "---\n",
    "\n",
    "If we know $G$ for the continuous problem, then it appears as if determining the discrete Green's function is rather trivial and we can use it to easily determine solutions through simple computations of inner products and sums of these inner products.\n",
    "\n",
    "Formally, we think of $G$ as the inverse of the differential operator $L$ applied to $\\delta(x-y)$, and we can think of the discrete Green's function in a similar way as the inverse of $L_h$ applied to $e^k$. This simply means that the discrete Green's funciton may be constructed by determining $\\frac{1}{h^2}A^{-1}$ and then multipling this to the standard basis vectors (scaled by $1/h$) of $\\mathbb{R}^n$. \n",
    "\n",
    "However, this is a ***stupid*** computation because it involves inverting a matrix, which is generally a computational expense we try to avoid whenever possible. \n",
    "\n",
    "Just like with regular Green's functions, which are really difficult to determine in general cases, the mere existence of one is usually enough to infer useful properties of the solution similar to how the existence of the inverse of a matrix is also useful even if we never construct it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b8e0d5-ec0b-4506-811a-4358e981242c",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### <a id='Section2.3.5'>Section 2.3.5: Convergence of Discrete Solutions to Continuous Solutions</a>\n",
    "---\n",
    "\n",
    "Here, the convergence is considered as $h=\\frac{1}{n+1}\\to 0$, which is equivalent to stating convergence as $n\\to\\infty$. We will ultimately show that if $u\\in \\mathcal{C}^2_0((0,1))$ is the continuous solution and $v\\in D_{h,0}$ is the discrete solution for the same $f\\in\\mathcal{C}^2([0,1])$, then $\\| u - v \\|_{h,\\infty} = \\mathcal{O}(h^2)$.\n",
    "\n",
    "We have numerically observed the convergence in [Section 2.2](https://github.com/CU-Denver-MathStats-OER/Intro-PDEs-Theory-and-Computations/blob/main/Chp2/Chp2Sec2.ipynb), but examples of numerical convergence are by no means a proof.\n",
    "\n",
    "To prove convergence, we first require definitions of truncation error and consistency, which are the key ingredients to proving convergence for solutions obtained via finite difference schemes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98348271-86a8-430e-a234-64ba7cfdc7f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "#### Definition 2.3.1: Truncation Error and Consistency\n",
    "\n",
    "Let $f\\in\\mathcal{C}([0,1])$ and $u\\in \\mathcal{C}^2_0((0,1))$ be the solution of the continuous BVP. Then, $\\tau_h\\in D_h^n$ defined by\n",
    "\n",
    "$$\n",
    "    \\tau_h(x_j) := (L_hu)(x_j) - f(x_j), \\ 1\\leq j\\leq n\n",
    "$$\n",
    "\n",
    "is called the **truncation error**. We say that the finite difference scheme encoded in the operator $L_h$ is **consistent** if\n",
    "\n",
    "$$\n",
    "    \\lim_{h\\downarrow 0} \\| \\tau_h \\|_{h,\\infty} = 0.\n",
    "$$\n",
    "\n",
    "---\n",
    "<br>\n",
    "\n",
    "**Remarks:**\n",
    "\n",
    "- Note that $\\tau_h$ is a discrete function defined by how well the *exact, continuous* solution satisfies the *discrete* problem.\n",
    "\n",
    "  There is no reason to believe that the continuous solution should exactly satisfy the discrete problem. However, we definitely have a problem if it does not *almost* solve this problem (meaning that $L_hu \\approx L_hv$ where $v$ is the *exact, discrete* solution). \n",
    "\n",
    "- We often refer to the truncation error as a vector in $\\mathbb{R}^n$ where the $j$th component of the vector is defined by the truncation error function evaluated at $x_j$. Given the isometries that exist between $D_h^n$ and $\\mathbb{R}^n$ with the $\\infty$-norm, this does not cause any problems.\n",
    "\n",
    "- Clearly, for finite difference schemes constructed by manipulating Taylor series/polynomials, truncation errors are related to the remainder term describing the error in a Taylor polynomial approximation. We therefore generally expect the truncation error to converge to zero for sufficiently smooth data. This is in fact key to the next two results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2025d31-bfd8-4b32-b508-05e5e72921c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "#### Lemma 2.3.4: Truncation Error\n",
    "\n",
    "Suppose $f\\in \\mathcal{C}^2([0,1])$, then \n",
    "\n",
    "$$\n",
    "    \\| \\tau_h \\|_{h,\\infty} \\leq \\frac{\\| f \\|_\\infty}{12} h^2.\n",
    "$$\n",
    "\n",
    "---\n",
    "<br>\n",
    "\n",
    "Before we prove this lemma, note that $f\\in\\mathcal{C}^2([0,1])$ is assumed smoother than we have considered before. This is critical to the proof as we see below. Another note is that we are bounding a norm for functions in $D_{h,0}$ with a norm for functions in $\\mathcal{C}([0,1])$.\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "***Proof of Lemma 2.3.4:***\n",
    "\n",
    "Let $1\\leq j\\leq n$. \n",
    "\n",
    "By the definition of $\\tau_h$, we have that for \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\left| \\tau_h(x_j) \\right| &= \\left| (L_hu)(x_j) - f(x_j) \\right| \\\\ \\\\\n",
    "                               &= \\left| \\frac{u(x_{j-1}) - 2u(x_j) + u(x_{j+1})}{h^2} + f(x_j) \\right|\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "By Theorem 2.1.1 (Existence, Uniqueness, and Smoothness), $f\\in\\mathcal{C}^2([0,1])$ implies $u\\in \\mathcal{C}^4_0((0,1))$. Thus, applying Taylor's theorem as was done for the analysis of the centered finite difference scheme in [Section 2.2](https://github.com/CU-Denver-MathStats-OER/Intro-PDEs-Theory-and-Computations/blob/main/Chp2/Chp2Sec2.ipynb), we have that\n",
    "\n",
    "$$\n",
    "    \\frac{u(x_{j-1}) - 2u(x_j) + u(x_{j+1})}{h^2} = u''(x_j) + \\frac{h^2}{24}\\left[u^{(4)}(\\xi_1) + u^{(4)}(\\xi_2) \\right]\n",
    "$$\n",
    "\n",
    "for some $\\xi_1\\in[x_{j-1}, x_j]$ and $\\xi_2\\in[x_j, x_{j+1}]$. Moreover, since $u$ is the exact solution to the continuous problem, we have that $-u''(x_j) = f(x_j)$, which implies $u''(x_j)=-f(x_j)$. This implies that\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\left| \\tau_h(x_j) \\right| &=  \\left| -f(x_j) + \\frac{h^2}{24}\\left[u^{(4)}(\\xi_1) + u^{(4)}(\\xi_2) \\right] + f(x_j) \\right| \\\\ \\\\\n",
    "                               &= \\frac{h^2}{24} \\left|u^{(4)}(\\xi_1) + u^{(4)}(\\xi_2)\\right| \\\\ \\\\\n",
    "                               &\\leq \\frac{\\|u^{(4)}\\|_\\infty}{12} h^2.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Since $-u''=f$, we have that $u^{(4)}=-f''$, which we substitute into the above inequailty above to give\n",
    "\n",
    "$$\n",
    "    \\left| \\tau_h(x_j) \\right| \\leq  \\frac{\\|f'' \\|_\\infty}{12} h^2.\n",
    "$$\n",
    "\n",
    "Since the term on the right is independent of $x_j$, applying the supremum over all $1\\leq j\\leq n$ to both sides gives the result.\n",
    "$\\Box$\n",
    "---\n",
    "<br>\n",
    "\n",
    "Note that the above is really just a different way of phrasing something we already knew from [Section 2.2](https://github.com/CU-Denver-MathStats-OER/Intro-PDEs-Theory-and-Computations/blob/main/Chp2/Chp2Sec2.ipynb) where we showed that \n",
    "\n",
    "$$\n",
    "    |E_h(x)| \\leq \\frac{M_g h^2}{12}, \n",
    "$$\n",
    "\n",
    "where $E_h$ is the remainder/error in approximating the second derivative of $g\\in\\mathcal{C}^4((0,1))$ at some point $x\\in(0,1)$. The difference here is mostly notation and the fact that we restrict the error analysis to solutions of the BVP at the grid points $x_j=jh$ for $1\\leq j\\leq n$.\n",
    "\n",
    "We are now in position to state and prove convergence.\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "#### Theorem 2.3.3: Convergence\n",
    "\n",
    "Suppose $f\\in\\mathcal{C}^2([0,1])$ and that $u\\in\\mathcal{C}^2_0((0,1))$ and $v\\in D_{h,0}$ are the continuous and discrete solutions of the corresponding continuous and discrete problems, respectively, then \n",
    "\n",
    "$$\n",
    "    \\| u - v \\|_{h,\\infty} \\leq \\frac{\\| f'' \\|_\\infty}{96}h^2.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "**Spoiler alert:** The $96$ is due to multiplying the $12$ appearing in Lemma 2.3.4 and the $8$ appearing in Theorem 2.3.2.\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "***Proof of Theorem 2.3.3:***\n",
    "\n",
    "Let $e\\in D_{h,0}$ be defined as $e(x_j):= u(x_j)-v(x_j)$ for $1\\leq j\\leq n$. \n",
    "\n",
    "Since $v$ is the *exact, discrete* solution, $L_hv(x_j) = f(x_j)$ for $1\\leq j\\leq n$. \n",
    "\n",
    "Let $1\\leq j\\leq n$, then the linearity of $L_h$ thus implies that\n",
    "\n",
    "$$\n",
    "    L_he(x_j) = L_hu(x_j)-L_hv(x_j) = L_hu(x_j)-f(x_j) = \\tau_h(x_j).\n",
    "$$\n",
    "\n",
    "Thus, $L_he = \\tau_h$, which means that $e$ is the *exact, discrete* solution to the BVP associated with the linear interpolant of $\\tau_h$. This implies that Theorem 2.3.1 (The Maximum Principle) applies to give\n",
    "\n",
    "$$\n",
    "    \\| e\\|_{h,\\infty}\\leq \\frac{1}{8}\\| \\tau_h \\|_{h,\\infty}.\n",
    "$$\n",
    "\n",
    "Applying Lemma 2.3.4 gives the result. $\\Box$\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "**Remarks:**\n",
    "\n",
    "- The above analysis is typical in that it utilizes an ***a priori error bound*** on $v\\in D_{h,0}$ that depends on a constant (in this case $\\frac{\\| f'' \\|_\\infty}{96}$) that is *independent* of the mesh/grid multipled by a function of the grid size (the $h^2$). The constant only depends upon the known data $f$. \n",
    "\n",
    "- The convergence is then \"clear\" once this bound is established because $\\lim_{h\\to 0} Ch^2 = C\\lim_{h\\to 0} h^2 = 0$ follows from standard convergence results in elementary analysis.\n",
    "\n",
    "- We say **a priori** here because the bound is known before the solutions. **A posteriori** error bounds (or even better, error estimates) are possible to construct with some more advanced techniques. We introduce some ideas related to that in [Section 2.4](https://github.com/CU-Denver-MathStats-OER/Intro-PDEs-Theory-and-Computations/blob/main/Chp2/Chp2Sec4.ipynb), which is perhaps best considered as an appendix to this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c77e25b-c73c-4c80-a78e-4a46d71cb78c",
   "metadata": {},
   "source": [
    "---\n",
    "#### Student Activity\n",
    "---\n",
    "\n",
    "Consider the differential equation\n",
    "\n",
    "$$\n",
    "    -u''(x)+u(x) = f(x), \\ x\\in(0,1), \\ u(0)=u(1)=0.\n",
    "$$\n",
    "\n",
    "1. Define $L$ and use the centered finite difference approximation for $-u''$ to define $L_h$.\n",
    "\n",
    "2. Define and compute the truncation error $\\tau_h$.\n",
    "\n",
    "3. Show that the scheme is consistent provided that the solution $u$ is sufficiently smooth.\n",
    "\n",
    "4. Provide some code/numerical examples/plots with manufactured solutions to illustrate these results.\n",
    "\n",
    "**Students are encouraged to try this on their own. However, solutions (at least partial solutions) are provided below in hidden cells that students can unhide if they get stuck while attempting this.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6da6d1-ff15-4232-a9e6-5f938ff0d742",
   "metadata": {},
   "source": [
    "**Student Activity Solution to Part 1.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffe8db3-759d-4f04-a81c-6676ca568c52",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "It is straightforward to define differential operators as standalone operators using derivative notation, so $L:\\mathcal{C}_0^2((0,1))\\to \\mathcal{C}((0,1))$ is defined by\n",
    "\n",
    "$$L:=-\\frac{d}{dx^2}+I.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5265cf72-7c16-4454-8edf-5e2feab223a2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "It is not as clean to define $L_h$ as a standalone operator. It is easier to define it in terms of its action $L_h: D_{h,0} \\to D_{h}^n$, so for $w\\in D_{h,0}$, we define\n",
    "\n",
    "$$\n",
    "    (L_hw)(x_j) := - \\frac{w(x_{j+1}) - 2w(x_j) + w(x_{j-1})}{h^2} + w(x_j), \\ \\text{ for } 1\\leq j \\leq n. \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b606d4c9-423d-4b83-aa0e-676eebe4cbc1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "If you wanted to define $L_h$ as a standalone operator, then use a notation like $\\delta_j:D_h\\to \\mathbb{R}$ to denote the operator that maps a function in $D_h$ to its evaluation at $x_j$, i.e., $\\delta_j w = w(x_j)$, and then you can write\n",
    "\n",
    "$$\n",
    "    L_h := -\\frac{1}{h^2}\\left(\\delta_{j+1} - 2\\delta_j + \\delta_{j-1}\\right) + \\delta_j , \\ \\text{ for } 1\\leq j\\leq n.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd8dd33-7089-4603-b895-6286c1ea65b8",
   "metadata": {},
   "source": [
    "**Student Activity Solution to Part 2.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ea3844-6a83-467a-8757-c7a3ceaa8c33",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "The truncation error $\\tau_h\\in D_h^n$ is defined by\n",
    "\n",
    "$$\n",
    "    \\tau_h(x_j) := (L_hu)(x_j) - f(x_j), \\ 1\\leq j\\leq n,\n",
    "$$\n",
    "\n",
    "i.e., it is the residual of exact continuous solution plugged into the discrete problem. In this problem, this means\n",
    "\n",
    "$$\n",
    "    \\tau_h(x_j) = - \\frac{u(x_{j+1}) - 2u(x_j) + u(x_{j-1})}{h^2} + u(x_j) - f(x_j), \\ 1\\leq j\\leq n.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680f6236-5f67-4d1e-9723-721f787d504d",
   "metadata": {},
   "source": [
    "**Student Activity Solution to Part 3.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7f293d-bcad-49aa-81be-20ec95d41b56",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "    \\left| \\tau_h(x_j) \\right| &= \\left| (L_hu)(x_j) - f(x_j) \\right| \\\\ \\\\\n",
    "                               &= \\left| \\frac{u(x_{j-1}) - 2u(x_j) + u(x_{j+1})}{h^2} -u(x_j) + f(x_j) \\right|\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Assuming $u$ is smooth enough (meaning it has at least four derivatives here), \n",
    "\n",
    "$$\n",
    "    \\frac{u(x_{j-1}) - 2u(x_j) + u(x_{j+1})}{h^2} = u''(x_j) + \\frac{h^2}{24}\\left[u^{(4)}(\\xi_1) + u^{(4)}(\\xi_2) \\right]\n",
    "$$\n",
    "\n",
    "for some $\\xi_1\\in[x_{j-1}, x_j]$ and $\\xi_2\\in[x_j, x_{j+1}]$. Moreover, since $u$ is the exact solution to the continuous problem, we have that $-u''(x_j) + u(x_j) = f(x_j)$, which implies $u''(x_j)-u(x_j)=-f(x_j)$. This implies that\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\left| \\tau_h(x_j) \\right| &=  \\left| -f(x_j) + \\frac{h^2}{24}\\left[u^{(4)}(\\xi_1) + u^{(4)}(\\xi_2) \\right] + f(x_j) \\right| \\\\ \\\\\n",
    "                               &= \\frac{h^2}{24} \\left|u^{(4)}(\\xi_1) + u^{(4)}(\\xi_2)\\right| \\\\ \\\\\n",
    "                               &\\leq \\frac{\\|u^{(4)}\\|_\\infty}{12} h^2.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Since $-u'' + u=f$, we have that $u^{(4)}=-f''+u''=-f''-f+u$, which we substitute into the above inequailty and apply the triangle inequality two times to get\n",
    "\n",
    "$$\n",
    "    \\left| \\tau_h(x_j) \\right| \\leq  \\frac{\\|f'' \\|_\\infty+\\|f \\|_\\infty+\\|u \\|_\\infty}{12} h^2.\n",
    "$$\n",
    "\n",
    "This is kind of annoying because we would prefer to write the truncation error in terms of just the data $f$, so we make use of the fact that there exists a Green's function for this problem (we saw this in Section 2.1) that is also bounded, so \n",
    "\n",
    "$$\n",
    "    u(x) = \\int_0^1 G(x,y)f(y)\\, dy,\n",
    "$$\n",
    "\n",
    "where $G(x,y)$ is the function seen in Section 2.1 and since $C=\\sup_{x\\in[0,1]}\\int_0^1 |G(x,y)|\\, dy<\\infty$, this means that\n",
    "\n",
    "$$\n",
    "    \\|u\\|_\\infty \\leq C\\|f\\|_\\infty,\n",
    "$$\n",
    "\n",
    "which means that\n",
    "\n",
    "$$\n",
    "    \\left| \\tau_h(x_j) \\right| \\leq  \\frac{\\|f'' \\|_\\infty+(C+1)\\|f \\|_\\infty}{12} h^2\\to 0 \\text{ as } h\\to 0.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d919ea-6df7-41eb-be53-3385f20c3d54",
   "metadata": {},
   "source": [
    "**Student Activity Solution to Part 4.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c07a76a-33e7-4384-b46b-2d748ecf462d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Activity 2.3.1 Part 4\n",
    "\n",
    "def solve_Lh_b(n, f):  # This is saying \"Construct $L_h^{-1}f$\" for this activity.\n",
    "    \n",
    "    A = make_A(n)  # Construct $A$\n",
    "    \n",
    "    x = np.linspace(0, 1, n+2)  # Create the n+2 grid points\n",
    "    h = x[1]-x[0]  # Determine h=1/(n+1), which is also just the difference between grid points\n",
    "    b = h**2*f(x[1:-1])  # Construct $b$\n",
    "    \n",
    "    # Note that v is a n+2 dimensional vector that is storing what we mean by $L_h^{-1}f$\n",
    "    v = np.zeros(n+2)  \n",
    "    \n",
    "    v[1:-1] = np.linalg.solve(A+np.eye(n), b)  \n",
    "    \n",
    "    return v, x, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ea7468-1fd4-4a99-bf1e-7fee419d6711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5243e6bf-4fca-47a2-a8b0-f32482a41eff",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "#### Student Activity \n",
    "---\n",
    "\n",
    "By Theorem 2.3.3, we have that for $e=u-v$ for the original BVP considered in this notebook that \n",
    "\n",
    "$$\n",
    "    \\|e\\|_{h, \\infty} \\leq \\frac{\\| f'' \\|_\\infty}{96}h^2\n",
    "$$\n",
    "\n",
    "Suppose we want the error in the numerical approximation $v\\approx u$ to be less than $1e-k$ for some $k\\in\\mathbb{N}$ at every grid point, then we can \"bound the bound\" and substitute $h=\\frac{1}{n+1}$ to determine the number of interior grid poitns $n$ that will *guarantee* the desired error tolerance is achieved.\n",
    "\n",
    "- Define some functions $f$ based on manufactured solutions and use the suggested approach above with an error tolerance of $1e-5$ that lead to $n>1e3$ and $n>1e4$.\n",
    "\n",
    "- Demonstrate the $n$ leads to the desired error tolernace in code cells below.\n",
    "\n",
    "*Hint: Smooth functions that have large second derivatives are often the result of the repeated application of the chain rule.*\n",
    "\n",
    "*Looking ahead: Suppose we wanted to control the error only at a few points, say $x=0.25$ and $x=0.66$. Can you create a finite difference scheme based on a non-uniform mesh to achieve the desired error tolerance at only these points with singificantly less grid points? Is this necessary? We will consider adjoint based a posteriori error estimation in the next notebook, which provides an alternative approach.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ba015a-4653-4db6-af4f-29c6bd385651",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fe3473-fd0c-4e6c-b793-765138fee0d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55e52ac-3a60-4c8f-b09c-95702d0d671d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de1e8e1-768f-4f55-a8cf-0f5d1d394893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86e2afad-b4ae-4afd-ae09-0d71c0662a4c",
   "metadata": {},
   "source": [
    "---\n",
    "## Navigation:\n",
    "\n",
    "- [Previous](https://github.com/CU-Denver-MathStats-OER/Intro-PDEs-Theory-and-Computations/blob/main/Chp2/Chp2Sec2.ipynb)\n",
    "\n",
    "- [Next](https://github.com/CU-Denver-MathStats-OER/Intro-PDEs-Theory-and-Computations/blob/main/Chp2/Chp2Sec4.ipynb)\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
