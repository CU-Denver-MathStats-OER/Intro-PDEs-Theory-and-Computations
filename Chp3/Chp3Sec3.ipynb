{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abc79548-e757-4dca-947b-8adf38080bd8",
   "metadata": {},
   "source": [
    "# Introduction to Partial Differential Equations\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43202de4-c968-4ff0-9258-79020bd7c57a",
   "metadata": {},
   "source": [
    "## Chapter 3: Parabolic PDEs, the Heat Equation, and a Deep Dive into Fourier Series \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c70b4f-d6d9-4c26-8e24-8dfd48ad96ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Creative Commons License Information\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc/4.0/80x15.png\" /></a><br /><span xmlns:dct=\"http://purl.org/dc/terms/\" property=\"dct:title\">Introduction to Partial Differential Equations: Theory and Computations</span> by <a xmlns:cc=\"http://creativecommons.org/ns#\" href=\"https://github.com/CU-Denver-MathStats-OER/Intro-PDEs-Theory-and-Computations\" property=\"cc:attributionName\" rel=\"cc:attributionURL\">Troy Butler</a> is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\">Creative Commons Attribution-NonCommercial 4.0 International License</a>.<br />Based on a work at <a xmlns:dct=\"http://purl.org/dc/terms/\" href=\"https://github.com/CU-Denver-MathStats-OER/Intro-PDEs-Theory-and-Computations\" rel=\"dct:source\">https://github.com/CU-Denver-MathStats-OER/Intro-PDEs-Theory-and-Computations</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b1265a-ccb8-455f-b3eb-97f224e7dcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib widget \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861fc71d-e374-4021-80e1-90ca4505c98a",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3.3: Fourier Series (A Rite of Passage)\n",
    "---\n",
    "\n",
    "This section primarily focuses on the summary of definitions and theory for general [Fourier series](https://en.wikipedia.org/wiki/Fourier_series). \n",
    "\n",
    "> **Author's note 1:** The first draft of this notebook was made when my son was seven years old and obsessed with the progressive rock band [Dream Theater](https://dreamtheater.net/). Admittedly, and quite self-servingly, I got him addicted to this amazing band so that we could listen to the music whenever we were in \"daddy's car.\" At any rate, as I was listening to my specially curated [playlist of Dream Theater](https://youtube.com/playlist?list=PLY1XMFiPjeiBeDp4RkuYAb3sku5BNvRRb) while simultaneously pondering how to present Fourier series, inspiration struck as to how I should organize this content around Dream Theater albums, songs, and lyrics. Perhaps this will amuse the future reader of this notebook (be it instructor or student). Perhaps it will annoy them (and for that, I am deeply sorry you are living a life filled with such terrible taste in music). I did this for me. I did this for my son. I hope you enjoy it. It was fun putting this together. Most of my allusions to Dream Theater are quite obvious/explicit. Can you catch them all? And, can you figure out *why* I made the associations I did?  \n",
    "\n",
    "> **Author's note 2:** Another useful reference is Chapter 4 of the OER textbook [Partial Differential Equations by Victor Ivrii](http://www.math.toronto.edu/ivrii/PDE-textbook/PDE-textbook.pdf) released under a Creative Commons Attribution-ShareAlike 4.0 International License. Several of the proofs and outlines of arguments for various results were heavily influenced and borrowed in large part from this reference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bd1506-cb56-41ce-a778-e56d1d19795a",
   "metadata": {},
   "source": [
    "---\n",
    "### Section 3.3.1: (Some) Scenes from a Memory\n",
    "---\n",
    "\n",
    "**A Strange Déjà Vu.** \n",
    "\n",
    "When you create a visual representation of [vectors](https://en.wikipedia.org/wiki/Vector_(mathematics_and_physics)) in $\\mathbb{R}^3$ in your mind, what do you see? Do you see 3-D arrows? The arrows point to something, but what is it that they point at?\n",
    "\n",
    "![Vectors from Gram-Schmidt process](https://upload.wikimedia.org/wikipedia/commons/e/ee/Gram-Schmidt_orthonormalization_process.gif)\n",
    "\n",
    "Mathematically we represent a vector in $v\\in\\mathbb{R}^3$ as an array of numbers such as\n",
    "\n",
    "$$\n",
    "    v = \\begin{pmatrix}\n",
    "            v_1 \\\\\n",
    "            v_2 \\\\\n",
    "            v_3\n",
    "        \\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "Here, $v_1, v_2$ and $v_3$ are real numbers representing the components of $v$. Once we become comfortable (or at least familiar enough) with the mathematical rules governing how we interact with vectors, we often think nothing more of this. But, there is a deeper story to be told.\n",
    "\n",
    "Let $e^{(1)}, e^{(2)}$ and $e^{(3)}$ denote the *standard basis vectors* in $\\mathbb{R}^3$ defined by \n",
    "\n",
    "$$\n",
    "    e^{(1)} = \\begin{pmatrix}\n",
    "            1 \\\\\n",
    "            0 \\\\\n",
    "            0\n",
    "        \\end{pmatrix}, \\ \n",
    "    e^{(2)} = \\begin{pmatrix}\n",
    "            0 \\\\\n",
    "            1 \\\\\n",
    "            0\n",
    "        \\end{pmatrix}, \\ \\text{ and } \\\n",
    "    e^{(3)} = \\begin{pmatrix}\n",
    "            0 \\\\\n",
    "            0 \\\\\n",
    "            1\n",
    "        \\end{pmatrix}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47a12b7-961b-4175-b724-2e79e495803a",
   "metadata": {},
   "source": [
    "**Through My Words.** \n",
    "\n",
    "Each of these basis vectors represents a *fundamental direction* in $\\mathbb{R}^3$. It is common to refer to $e^{(1)}$ as *pointing* in the $x$-direction, $e^{(2)}$ as *pointing* in the $y$-direction, and $e^{(3)}$ as *pointing* in the $z$-direction. This is common because it is intuitive. It matches our typical mathematical description of 3-D space in terms of orthorgonal $x$-, $y$-, and $z$-axes and our visual conceptualization of vectors as arrows that point.\n",
    "\n",
    "We also see that if $\\langle \\cdot, \\cdot \\rangle$ denotes the typical inner product structure on $\\mathbb{R}^3$, then $v_1 = \\langle v, e^{(1)} \\rangle$, $v_2 = \\langle v, e^{(2)} \\rangle$, and $v_3 = \\langle v, e^{(3)} \\rangle$. Moreover, we can rewrite $v\\in\\mathbb{R}^3$ as\n",
    "\n",
    "$$\n",
    "    v = v_1e^{(1)} + v_2e^{(2)} + v_3e^{(3)}.\n",
    "$$\n",
    "\n",
    "This means that although $v$ is a single vector, it can be decomposed as the sum of three vectors. If we think of each vector as describing a way of traveling through the space in which the vector exists, then we may think of traveling $v_1$ units in the $x$-direction, then \"turning 90 degrees\" in the $xy$-plane, we travel $v_2$ units in the $y$-direction, and finally, \"turning another 90 degrees\" (this time in the $yz$-plane), we travel a final $v_3$ units to arrive at the desired location at the tip of the arrow of $v$. \n",
    "\n",
    "We can easily generalize the above description to vectors in $n$-dimensional Euclidean space, $\\mathbb{R}^n$ for an arbitrarily large positive integer $n$. We do this by considering the standard basis vectors of the form $e^{(i)}\\in\\mathbb{R}^n$,  for $1\\leq i\\leq n$, that have a $1$ in the $i$th coordinate and a $0$ everywhere else.\n",
    "\n",
    "None of this, of course, is profound. We are often exposed to this idea of vectors in a first-semester linear algebra course (or perhaps before that a multivariable calculus course). But, this hints at deeper ideas that, while also introduced and considered (if ever so briefly) in a first-semester linear algebra course, are also perhaps not fully appreciated at the time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079e674c-a924-48f8-8560-02fc4b0a0b3f",
   "metadata": {},
   "source": [
    "**Fatal Tragedy (of standard basis vectors).** \n",
    "\n",
    "We are not always interested in using the standard basis vectors. These represent, after all, a standard representation of the Euclidean space (of whatever dimension we are considering). However, there are plenty of applications where we wish to, for lack of a better term, orient ourselves in the space in a manner different from the standard approach. For instance, when the space is, for lack of a better term, warped by a mapping, then representing vectors as a summation of the standard basis vectors can unwittingly hide useful insights into how these vectors are situated in the space with respect to the mapping. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e5e160-e2e0-4991-850c-04f09562cf02",
   "metadata": {},
   "source": [
    "**Beyond This Life (of standard basis vectors).** \n",
    "\n",
    "Consider, for instance, the standard linear mapping of a space into itself with a symmetric positive definite matrix $A\\in\\mathbb{R}^{n\\times n}$. Assume, for the sake of simplicity, that $A$ has $n$ distinct positive eigenvalues denoted by $\\lambda_1, \\ldots, \\lambda_n$, and $v^{(1)}, \\ldots, v^{(n)}$ are the associated eigenvectors. Then, $Av^{(i)} = \\lambda_i v^{(i)}$ for each $1\\leq i\\leq n$. We also have that\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "   \\color{red}{\\lambda_i }\\langle  v^{(i)},  v^{(j)} \\rangle &= \\langle  \\color{red}{\\lambda_i} v^{(i)},  v^{(j)} \\rangle \\\\\n",
    "                                                         \\\\\n",
    "                                                         &= \\langle  Av^{(i)},  v^{(j)} \\rangle \\\\\n",
    "                                                         \\\\\n",
    "                                                         &= \\langle  v^{(i)}, A^\\top v^{(j)} \\rangle \\\\\n",
    "                                                         \\\\\n",
    "                                                         &= \\langle  v^{(i)}, A v^{(j)} \\rangle \\\\\n",
    "                                                         \\\\\n",
    "                                                         &= \\langle  v^{(i)}, \\color{darkcyan}{\\lambda_j} v^{(j)} \\rangle \\\\\n",
    "                                                         \\\\\n",
    "                                                         &= \\color{darkcyan}{\\lambda_j} \\langle  v^{(i)}, v^{(j)} \\rangle.\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d663260c-42e0-4e64-aae0-d3829d2d628d",
   "metadata": {},
   "source": [
    "**Through Her Eyes (an eigenbasis).** \n",
    "\n",
    "This means that $\\color{red}{\\lambda_i}  \\langle  v^{(i)},  v^{(j)} \\rangle = \\color{darkcyan}{\\lambda_j} \\langle  v^{(i)}, v^{(j)} \\rangle$, or, to put it another way, $\\color{red}{\\lambda_i} \\alpha = \\color{darkcyan}{\\lambda_j} \\alpha$ where $\\alpha = \\langle  v^{(i)}, v^{(j)} \\rangle$. Since $\\color{red}{\\lambda_i}\\neq\\color{darkcyan}{\\lambda_j}$ whenever $i\\neq j$ by assumption, this can only be true if $\\alpha=0$. This of course means that the eigenvectors are *orthogonal* to each other. We are free to choose non-trivial scalar multiples of each eigenvector to describe the eigenspace associated with each eigenvector, and we might as well choose them so that $\\langle v^{(i)}, v^{(i)} \\rangle = 1$ for $1\\leq i\\leq n$. Such a choice then defines an *orthonormal basis* for $\\mathbb{R}^n$. \n",
    "\n",
    "This is a very useful basis because if we consider any $v\\in\\mathbb{R}^n$, we immediately have that\n",
    "\n",
    "$$\n",
    "    v = \\tilde{v}_1 v^{(1)} + \\tilde{v}_2 v^{(2)} + \\cdots \\tilde{v}_n v^{(n)}, \n",
    "$$\n",
    "\n",
    "where, by the assumed orthonormality of the eigenvectors, we have that\n",
    "\n",
    "$$\n",
    "    \\tilde{v}_1 = \\langle v, v^{(1)} \\rangle, \\ \\tilde{v}_2 = \\langle v, v^{(2)} \\rangle, \\ \\ldots \\, \\tilde{v}_n = \\langle v, v^{(n)}\\rangle.\n",
    "$$\n",
    "\n",
    "This decomposition of $v$ in terms of the orthonormal basis described by the eigenvectors of $A$ is incredibly useful because it tells us immediately what $Av$ is *without ever having to compute the matrix-vector product*. Instead, we can simply write\n",
    "\n",
    "$$\n",
    "    Av = \\lambda_1 \\tilde{v}_1 v^{(1)} + \\lambda_2\\tilde{v}_2 v^{(2)} + \\cdots \\lambda_n\\tilde{v}_n v^{(n)}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c712f8-f965-4d19-8f72-ce77c3465a79",
   "metadata": {},
   "source": [
    "**(Bringing it all) Home.** \n",
    "\n",
    "What the equation above means is that it is more useful to \"orient our perspective\" in such a way in the $\\mathbb{R}^n$ space so that we think of an arbitrary vector $v$ as the summation of eigenvectors, $v^{(i)}$ for $1\\leq i\\leq n$, that are themselves arrows pointing in directions *preferred by $A$* in the sense that the direction of these arrows remains unchanged when transformed by $A$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3eb6da8-550e-4ad3-b22d-4883b475a93a",
   "metadata": {},
   "source": [
    "---\n",
    "### Section 3.3.2: (Some Additional) Scenes from a Memory\n",
    "---\n",
    "\n",
    "**The Dance of Eternity (and an infinite-dimensional vector space).** \n",
    "\n",
    "The basic concept behind a Fourier series is that the trigonmetric family of functions defined by \n",
    "\n",
    "$$\n",
    "    \\left\\{ \\frac{1}{2}, \\ \\cos(k\\pi x), \\ \\sin(k\\pi x), \\ k=1, 2, \\ldots \\right\\}\n",
    "$$\n",
    "\n",
    "forms an [orthogonal basis](https://en.wikipedia.org/wiki/Orthogonal_basis) for functions in [$L^2([-1,1])$](https://en.wikipedia.org/wiki/Square-integrable_function). In other words, if $f$ is a square integrable function on $[-1, 1]$, then we can write $f(x)$ as a (possibly infinite) linear combination of functions taken from this basis. Moreover, since an $L^2$ space is an inner product space (defined by the integration of the product of two $L^2$ functions) and the basis functions are in fact an orthogonal basis, then the coefficients used in the linear combination are easily determined by integrating $f$ against each of these basis functions and appropriately scaling by the square of the $L^2([-1,1])$ norm of each basis vector. In this case, $\\|\\frac{1}{2}\\|_{L^2([-1,1])}^2 = \\frac{1}{2}$ whereas $\\|\\cos(k\\pi x)\\|_{L^2([-1,1])}^2$ = 1 and $\\|\\sin(k\\pi x)\\|_{L^2([-1,1])}^2$ = 1 for each $k\\in\\mathbb{N}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fd2481-02f3-44e7-b8ac-6c455e7f01e1",
   "metadata": {},
   "source": [
    "**One Last Time.** \n",
    "\n",
    "It is worth emphasizing, just one last time, how eigenvectors are useful vectors for forming a basis. We have seen how sine functions show up as eigenfunctions associated with certain two-point BVPs with homogeneous Dirichlet BCs. We would have seen cosine functions as eigenfunctions if the BCs were of Neumann type. Committing this to memory is a good idea.\n",
    "\n",
    "Another useful note is that if $f(y)$ is a real-valued function defined for $y\\in[0,P]$, then redefining the domain through a change of variables $y(x)=\\frac{P(x+1)}{2}$ allows us to define \"$f(x)$\" (meaning $f(y(x))$) as a function on $[-1,1]$, which we find convenient here.\n",
    "\n",
    "We therefore assume for simplicity that the functions considered in this notebook are defined on $[-1,1]$ unless otherwise specified. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65305562-4740-460b-bd86-f442ddc02768",
   "metadata": {},
   "source": [
    "**The Spirit Carries On.** \n",
    "\n",
    "For such a function $f$, the full Fourier series is given by\n",
    "\n",
    "$$\n",
    "    f(x) \"=\" \\frac{a_0}{2} + \\sum_{k=1}^\\infty \\left(a_k\\cos(k\\pi x) + b_k\\sin(k\\pi x)\\right), \n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "    a_k := \\int_{-1}^1 f(x)\\cos (k\\pi x)\\, dx, \\ k=0, 1, 2, \\ldots, \n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "    b_k := \\int_{-1}^1 f(x)\\sin (k\\pi x)\\, dx, \\ k=1, 2, 3, \\ldots.\n",
    "$$\n",
    "\n",
    "This truly is in the spirit of what we have seen before for finite-dimensional vectors written in terms of a convenient basis (such as an orthonormal basis of eigenvectors). If we let $\\langle \\cdot, \\cdot \\rangle$ denote the $L^2$ inner product on $[-1,1]$, then we see that each of the coefficients of the Fourier series is simply given as $\\langle f, v^{(i)}\\rangle$ where $v^{(i)}$ is one of the functions from the trigonometric family given above.\n",
    "\n",
    "- Note that if we considered the interval $[-\\ell, \\ell]$ for some $\\ell>0$, then the integrals would have a multiplicative factor of $1/\\ell$ applied to them and the arguments for the cosine and sine functions in the integrand would be divided by $\\ell$ as well. Thus, choosing $\\ell=1$ simplifies the presentation. If $\\ell\\neq 1$ and one does not wish to rescale the interval to $[-1,1]$, then simply make these modifications to obtain the correct coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726b42de-108d-4af0-9c11-20900afa11a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import quad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f1461b-1ca0-4049-bb48-d03691ee1c5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_a_k(f, k):\n",
    "    integrand = lambda x: f(x)*np.cos(k*np.pi*x)\n",
    "    a_k = quad(integrand, -1, 1)[0]  # Use quadrature to integrate\n",
    "    if np.abs(a_k) < 1e-7:  # Filter out \"numerically zero\" integrals\n",
    "        return 0\n",
    "    else:\n",
    "        return a_k  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46939044-324f-49a2-82ae-a10459673537",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_b_k(f, k):\n",
    "    integrand = lambda x: f(x)*np.sin(k*np.pi*x)\n",
    "    b_k = quad(integrand, -1, 1)[0]  # Use quadrature to integrate\n",
    "    if np.abs(b_k) < 1e-7:  # Filter out \"numerically zero\" integrals\n",
    "        return 0\n",
    "    else:\n",
    "        return b_k "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b791be8-600a-4188-9124-9609f1d1a487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_Fourier_expansion_coeffs(f, k):\n",
    "    \n",
    "    # Compute Fourier coeffs up to and including order k\n",
    "    a_k = np.zeros(k+1)\n",
    "    b_k = np.zeros(k)\n",
    "    \n",
    "    a_k[0] = compute_a_k(f, 0)\n",
    "    \n",
    "    for i in range(1, k+1):\n",
    "        a_k[i] = compute_a_k(f, i)\n",
    "        b_k[i-1] = compute_b_k(f, i)\n",
    "        \n",
    "    return a_k, b_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b787d9-4d99-42c7-a096-d1044237a9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_Fourier_expansion(a_k, b_k, x):\n",
    "    \n",
    "    partial_sum = a_k[0]/2\n",
    "    for i in range(1, len(b_k)+1):\n",
    "        partial_sum += a_k[i]*np.cos(i*np.pi*x) + b_k[i-1]*np.sin(i*np.pi*x)\n",
    "    \n",
    "    return partial_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebfd909-5a08-45cb-bcd9-82ad1cadea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: 1\n",
    "\n",
    "a_k, b_k = construct_Fourier_expansion_coeffs(f, 10)\n",
    "\n",
    "print(a_k)\n",
    "print(b_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eba36c3-5d37-46a5-b7a4-7f77a8f9e346",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_Fourier = lambda x: evaluate_Fourier_expansion(a_k, b_k, x)\n",
    "\n",
    "x = np.linspace(-1, 1, 100)\n",
    "\n",
    "print(f_Fourier(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd38670-a367-462d-aec9-87b204b8d345",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: x\n",
    "\n",
    "a_k, b_k = construct_Fourier_expansion_coeffs(f, 10)\n",
    "\n",
    "print(a_k)\n",
    "print(b_k)\n",
    "\n",
    "f_Fourier = lambda x: evaluate_Fourier_expansion(a_k, b_k, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb40aa6-59f9-475f-b9e8-8b017cba61ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "plt.figure(0)\n",
    "\n",
    "x_domain = np.linspace(-1, 1, 100)\n",
    "x_extension = np.linspace(-3, 3, 300)\n",
    "\n",
    "plt.plot(x_extension, f_Fourier(x_extension), 'r', label='Fourier approx. on $\\mathbb{R}$')\n",
    "plt.plot(x_domain, f(x_domain), 'b', lw=2, label='f(x) on [-1,1]')\n",
    "\n",
    "plt.legend(fontsize=12, shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a342e2-57fd-45da-af88-27c51d5ea403",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: np.heaviside(x+0.5, 1) - np.heaviside(x-0.5, 1)\n",
    "\n",
    "a_k, b_k = construct_Fourier_expansion_coeffs(f, 10)\n",
    "\n",
    "print(a_k)\n",
    "print(b_k)\n",
    "\n",
    "f_Fourier = lambda x: evaluate_Fourier_expansion(a_k, b_k, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19012c1-d297-4d7f-971a-3cd3930bb118",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "plt.figure(1)\n",
    "\n",
    "x_domain = np.linspace(-1, 1, 100)\n",
    "x_extension = np.linspace(-3, 3, 300)\n",
    "\n",
    "plt.plot(x_extension, f_Fourier(x_extension), 'r', label='Fourier approx. on $\\mathbb{R}$')\n",
    "plt.plot(x_domain, f(x_domain), 'b', lw=2, label='f(x) on [-1,1]')\n",
    "\n",
    "plt.legend(fontsize=12, shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b870df-3167-4215-875f-d78e98406e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: x**3-2*x**2\n",
    "\n",
    "a_k, b_k = construct_Fourier_expansion_coeffs(f, 10)\n",
    "\n",
    "print(a_k)\n",
    "print(b_k)\n",
    "\n",
    "f_Fourier = lambda x: evaluate_Fourier_expansion(a_k, b_k, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791f5034-a0dc-4a63-bc27-a2dfd2a778ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "plt.figure(2)\n",
    "\n",
    "x_domain = np.linspace(-1, 1, 100)\n",
    "x_extension = np.linspace(-3, 3, 300)\n",
    "\n",
    "plt.plot(x_extension, f_Fourier(x_extension), 'r', label='Fourier approx. on $\\mathbb{R}$')\n",
    "plt.plot(x_domain, f(x_domain), 'b', lw=2, label='f(x) on [-1,1]')\n",
    "\n",
    "plt.legend(fontsize=12, shadow=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f06048-34cb-4b94-bde0-f7e3142c831a",
   "metadata": {},
   "source": [
    "**In the Presence of Enemies (both parts).**\n",
    "\n",
    "You may wonder why the Fourier series above is given in terms of *both* cosines and sines when [Section 3.2](Chp3Sec2.ipynb) involved Fourier series expansions only in terms of sines or cosines but not both. In the case of the the homogeneous Dirichlet BCs in Section 3.2, the cosine terms had to be excluded since they failed to satisfy these conditions (and similarly for why the sine terms were absent when studying the homogeneous Neumann BCs). \n",
    "\n",
    "Consequently, this is why the sine series expansion of the constant function $f(x)=1$ was so complicated in the previous section whereas in the case of the homogeneous Neumann BCs, the cosine expansion is a rather trivial expansion of $f(x)=1$ since $a_0=2$ and all other coefficients are zero in the expansion of this function (i.e., the \"general\" or \"full\" Fourier series expansion of $f(x)=1$ is simply $f(x)=1$ as shown in code above).\n",
    "\n",
    "For now, we focus more on the analysis of \"general\" Fourier series expansions (also called the \"full\" Fourier series expansion). In the last two subsections of this notebook, we discuss how the theory of these full Fourier series expansions applies to the Fourier sine and Fourier cosine series expansions and the justification for their use in solving the heat equation with different types of BCs. For now, we just note that *the theory does apply* (after some appropriate care and the proper perspective is taken) and a key observation is that the full Fourier series expansion involves computations of integrals over intervals that look like $[-1,1]$ (or more generally $[-\\ell, \\ell]$) while the Fourier sine and Fourier cosine series expansions involve integrals over intervals that look like $[0,\\ell]$ (or $[0,1]$ if $\\ell=1$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cf5247-6ef8-46e4-94ee-22a42b001930",
   "metadata": {},
   "source": [
    "**Finally Free (to ask the important question).** \n",
    "\n",
    "The most important question we need to address at this moment is\n",
    "\n",
    "> What is meant by the quotes around the equality, \"$=$\", connecting $f(x)$ and the infinite sum?\n",
    "\n",
    "After all, it appears in the examples above that there are some points of $f(x)$ where the Fourier series is approximating $f(x)$ quite well while there are other points where the Fourier series (for some functions) exhibits some serious oscillations. How do we make sense of this? How do we address convergence of the partial sums?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6574bec2-e6fb-49a0-8490-cb6f3d678576",
   "metadata": {},
   "source": [
    "We first answer this by describing the specific manner in which the sequence of partial sums converges to $f(x)$ or another value related to the \"nearby behavior\" of $f(x)$ at a specific fixed $x$ value in the interval $[-1,1]$. In other words, we address the pointwise convergence of the Fourier series. This requires us to consider properties of $f(x)$ at particular $x$ values. To that end, we formally define what it means for $f(x)$ to be piecewise-continuous and piecewise-continouusly differentiable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565336fd-9447-4f0b-b34f-2fb63d994c04",
   "metadata": {},
   "source": [
    "---\n",
    "### Section 3.3.3: (A Vision) Decay of Fourier Coefficients\n",
    "---\n",
    "\n",
    "Here, I follow the general presentation of Section 4.4 of the OER text [Partial Differential Equations](http://www.math.toronto.edu/ivrii/PDE-textbook/PDE-textbook.pdf) by Victor Ivrii, which I found to be well organized and thorough. \n",
    "\n",
    "The following definition sets up the pointwise properties of $f(x)$ that we will use to consider the manner in which the Fourier series converges to $f(x)$ at various points $x\\in[-1,1]$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2a0725-51fb-4bbc-814d-07081f2cd53b",
   "metadata": {},
   "source": [
    "---\n",
    "#### Definition 3.3.1: Piecewise-Continuity and Piecewise-Differentiability\n",
    "\n",
    "(a) $f(x)$ is ***piecewise-continuous*** on $[-1,1]$ if it is continuous except at a finite set of points and at those points of discontinuity, the one-sided limits exist.\n",
    "\n",
    "(b) $f(x)$ is ***piecewise-continuously differentiable*** if it is continuously differentiable except at a finite set of points and at those points, the one-sided limits of the derivative exist. \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3009cd5b-da7e-49dd-ad3e-db86bf70ee56",
   "metadata": {},
   "source": [
    "A result from a typical second-semester calculus course is that if a series has a finite sum, then the terms in the series must converge to zero. Of course, the converse is not true since the decay of terms to zero may be so slow that the series still diverges (recall the standard example of a harmonic series $\\sum_{k=1}^\\infty 1/k$ that diverges to infinity). At any rate, with this in mind, it should not come as a surprise that we have the following useful result regarding the decay of Fourier coefficients for piecewise-continuous functions.\n",
    "<br><br> \n",
    "\n",
    "---\n",
    "#### Lemma 3.3.1: Decay of Fourier Coefficients (Bridges in the Sky)\n",
    "\n",
    "If $f(x)$ is piecewise-continuous on $[-1,1]$, then $a_k\\to 0$ and $b_k\\to 0$ as $k\\to\\infty$. More generally, $\\int_{-1}^1 f(x)\\cos (\\omega x)\\, dx \\to 0$ and $\\int_{-1}^1 f(x)\\sin (\\omega  x)\\, dx \\to 0$ as $\\omega\\to\\infty$.\n",
    "\n",
    "---\n",
    "\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "***Idea of proof of Lemma 3.3.1.***\n",
    "\n",
    "1. First show that if $f(x)$ is continuously differentiable on $[-1,1]$, then integration by parts implies that $a_k=\\mathcal{O}(1/k)$ and $b_k=\\mathcal{O}(1/k)$.\n",
    "\n",
    "2. Now assume that $f(x)$ is only continuous on $[-1,1]$. A useful result from analysis is that $f(x)$ can be approximately arbitrarily accurately in the $\\sup$-norm metric by a continuously differentiable function. Use this to show that the difference between the Fourier coefficients for $f$ and its more smooth approximation can be made arbitrarily small and that by step 1 this implies $a_k\\to 0$ and $b_k\\to 0$.\n",
    "\n",
    "3. If $f(x)$ is piecewise-continuous, then break up the integral over $[-1,1]$ into the sum of integrals over the intervals on which $f(x)$ is continuous. Now use what was shown in step 2. \n",
    "\n",
    "4. Recognize that all the above arguments also hold with $\\omega\\to\\infty$ not necessarily being integers. $\\Box$\n",
    "\n",
    "---\n",
    "<br><br>\n",
    "\n",
    "**Remark:**\n",
    "\n",
    "- It is straightforward to see that the Lemma also gives $\\int_{-1}^1 f(x)\\cos ((\\omega -\\alpha)x + \\phi)\\, dx \\to 0$ and $\\int_{-1}^1 f(x)\\sin ((\\omega - \\alpha)x + \\phi)\\, dx \\to 0$ as $\\omega\\to\\infty$ for some fixed $\\alpha,\\phi\\in\\mathbb{R}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3648bdb8-b831-4b28-86f9-9989ef6d0d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: x**3-2*x**2\n",
    "\n",
    "a_k, b_k = construct_Fourier_expansion_coeffs(f, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46432f76-92d7-4fd1-87a8-27a270f69684",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "plt.figure(3)\n",
    "\n",
    "plt.loglog(np.linspace(0, 100, 101), np.abs(a_k), 'b:', label='$a_k$')\n",
    "\n",
    "plt.loglog(np.linspace(1, 100, 100), np.abs(b_k), 'r-.', label='$b_k$')\n",
    "\n",
    "plt.legend(fontsize=12, shadow=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3652e2-068c-4dad-8369-4a37511f32e9",
   "metadata": {},
   "source": [
    "---\n",
    "### Section 3.3.4: Convergence of Fourier Series (Part I: The X Aspect)\n",
    "---\n",
    "\n",
    "Let $S_N(x)$ denote the partial Fourier sum for a piecewise-continuous $f(x)$, i.e., \n",
    "\n",
    "$$\n",
    "    S_N(x) := \\frac{a_0}{2} + \\sum_{k=1}^N \\left(a_k\\cos(k\\pi x) + b_k\\sin(k\\pi x)\\right).\n",
    "$$\n",
    "\n",
    "Substituting the definitions of $a_k$ and $b_k$ into $S_N(x)$ and using the linearity of the integral operator, we have that\n",
    "\n",
    "$$\n",
    "    S_N(x) := \\int_{-1}^1 K_N(x,y) f(y)\\, dy, \n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "    K_N(x,y) := \\frac{1}{2} + \\sum_{k=1}^N \\left[ \\cos(k\\pi y)\\cos(k\\pi x) + \\sin(k\\pi y)\\sin(k\\pi x)\\right].\n",
    "$$\n",
    "\n",
    "Note how $K_N(x,y)$ serves a similar purpose as that of the Green's function, $G(x,y)$, that we encountered in [Section 2.1](../Chp2/Chp2Sec1.ipynb). Specifically, $K_N(x,y)$ and $G(x,y)$ are types of [kernel functions for an integral transform](https://en.wikipedia.org/wiki/Integral_transform) that turns some \"data\" (for lack of a better term) defined by $f(x)$ into a new function that we are interested in studying ($S_N(x)$ here and $u(x)$ in Section 2.1).\n",
    "\n",
    "<mark>**The game is to figure out how to use Lemma 3.3.1 to prove that $S_N(x)$ converges to $f(x)$ at certain values of $x$ and is otherwise related to the average value of $f(x)$ at nearby points of discontinuity.**</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5802cff-bc6a-4249-9b69-ed063cb358e9",
   "metadata": {},
   "source": [
    "**Six Degrees of Inner Turbulence.** \n",
    "\n",
    "We now play a game, and oh what a game it is, in how to use trigonometric identities/techniques to rewrite $K_N$ without the summation notation. To this end, we first use a [sum of angles formula for cosine](https://en.wikipedia.org/wiki/List_of_trigonometric_identities#Angle_sum_and_difference_identities) to get\n",
    "\n",
    "$$\n",
    "    K_N(x,y) = \\frac{1}{2} + \\sum_{k=1}^N \\cos(k\\pi(y-x)).\n",
    "$$\n",
    "\n",
    "While this simplifies $K_N$, we are still left with the summation notation. \n",
    "We can turn this summation into a telescoping sum.\n",
    "\n",
    "To do this, we first observe that manipulating a sum of angles formula for sine twice, we have\n",
    "\n",
    "$$\n",
    "    \\sin(\\alpha)\\cos(\\beta) = \\sin(\\alpha + \\beta) - \\cos(\\alpha)\\sin(\\beta)\n",
    "$$\n",
    "\n",
    "and \n",
    "\n",
    "$$\n",
    "    \\sin(\\alpha)\\cos(\\beta) = \\sin(\\alpha - \\beta) + \\cos(\\alpha)\\sin(\\beta), \n",
    "$$\n",
    "\n",
    "so adding these equations together and using the \"oddness\" of sine gives\n",
    "\n",
    "$$\n",
    "    \\sin(\\alpha)\\cos(\\beta) = \\frac{1}{2} \\left[\\sin(\\alpha + \\beta) - \\sin(\\beta - \\alpha)\\right].\n",
    "$$\n",
    "\n",
    "Choosing $\\beta = k\\pi(y-x)$ and $\\alpha=\\pi(y-x)/2$, we have\n",
    "\n",
    "$$\n",
    "    \\sin\\left(\\frac{\\pi(y-x)}{2}\\right)\\cos(k\\pi(y-x)) = \\frac{1}{2} \\left[\\sin\\left(\\left(k+\\frac{1}{2}\\right)\\pi(y-x)\\right) - \\sin\\left(\\left(k-\\frac{1}{2}\\right)\\pi(y-x)\\right)\\right].\n",
    "$$\n",
    "\n",
    "This implies that\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\sin\\left(\\frac{\\pi(y-x)}{2}\\right)K_N(x,y) &= \\frac{1}{2}\\sin\\left(\\frac{\\pi(y-x)}{2}\\right) + \\underbrace{\\frac{1}{2}\\sum_{k=1}^N \\left[\\sin\\left(\\left(k+\\frac{1}{2}\\right)\\pi(y-x)\\right) - \\sin\\left(\\left(k-\\frac{1}{2}\\right)\\pi(y-x)\\right)\\right]}_{\\text{telescoping sum}} \\\\\n",
    "                        \\\\\n",
    "                        &= \\frac{1}{2}\\sin\\left(\\frac{\\pi(y-x)}{2}\\right) + \\frac{1}{2}\\sin\\left(\\left(N+\\frac{1}{2}\\right)\\pi(y-x)\\right) - \\frac{1}{2}\\sin\\left(\\frac{\\pi(y-x)}{2}\\right) \\\\\n",
    "                        \\\\\n",
    "                        &=  \\frac{1}{2}\\sin\\left(\\left(N+\\frac{1}{2}\\right)\\pi(y-x)\\right).\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Thus, we get\n",
    "\n",
    "$$\n",
    "    K_N(x,y) = \\frac{\\sin\\left(\\left(N+\\frac{1}{2}\\right)\\pi(y-x)\\right)}{2\\sin\\left(\\frac{\\pi(y-x)}{2}\\right)},\n",
    "$$\n",
    "\n",
    "which implies that\n",
    "\n",
    "$$\n",
    "    S_N(x) = \\int_{-1}^1  \\frac{\\sin\\left(\\left(N+\\frac{1}{2}\\right)\\pi(y-x)\\right)}{2\\sin\\left(\\frac{\\pi(y-x)}{2}\\right)} f(y)\\, dy \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612b690f-74ab-4c4d-90f1-c9973678bb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_N(y, N, x):\n",
    "    return np.sin((N+0.5)*np.pi*(y-x)) / ( 2*np.sin(np.pi*(y-x)/2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a43585-90fc-4e0b-be16-d3d5e0a8f4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Think of the cost of this approach vs. computing the N coefficients\n",
    "\n",
    "def S_N(f, N, x):\n",
    "    v = np.zeros(len(x))\n",
    "    for i in range(len(x)):\n",
    "        integrand = lambda y, N, x: K_N(y, N, x)*f(y)\n",
    "        v[i] = quad(integrand, -1, 1, args=(N, x[i]))[0]\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c6411a-24d3-4931-ba68-75af830cfcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: np.heaviside(x+0.5, 1) - np.heaviside(x-0.5, 1)\n",
    "\n",
    "# f = lambda x: x\n",
    "\n",
    "N = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bfca8a-e248-43bf-ab5e-c82afb2b8585",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "plt.figure(4)\n",
    "\n",
    "x_domain = np.linspace(-1, 1, 100)\n",
    "x_extension = np.linspace(-3, 3, 300)\n",
    "\n",
    "plt.plot(x_extension, S_N(f, N, x_extension), 'r', label='Fourier approx. on $\\mathbb{R}$')\n",
    "plt.plot(x_domain, f(x_domain), 'b', lw=2, label='f(x) on [-1,1]')\n",
    "\n",
    "plt.legend(fontsize=12, shadow=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552eb47c-9c2b-4b12-aa01-6c82860177f4",
   "metadata": {},
   "source": [
    "**The Answer Lies Within.** \n",
    "\n",
    "Suppose that $f$ is a piecewise continuously differentiable function on $[-1,1]$. If $f$ is differentiable at $x\\in (-1,1)$ (note that $x$ is an interior point of the interval), then by adding and subtracting $f(x)$ to $f(y)$ and exploiting linearity of the integral, we have that\n",
    "\n",
    "$$\n",
    "    S_N(x) = \\underbrace{\\int_{-1}^1  \\frac{\\sin\\left(\\left(N+\\frac{1}{2}\\right)\\pi(y-x)\\right)}{2\\sin\\left(\\frac{\\pi(y-x)}{2}\\right)} (f(y)-f(x))\\, dy}_{\\mathbf{I}} + \\underbrace{\\int_{-1}^1  \\frac{\\sin\\left(\\left(N+\\frac{1}{2}\\right)\\pi(y-x)\\right)}{2\\sin\\left(\\frac{\\pi(y-x)}{2}\\right)} f(x)\\, dy}_{\\mathbf{II}}.\n",
    "$$\n",
    "\n",
    "The second integral, denoted by $\\mathbf{II}$, is equal to $f(x)$ because \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\mathbf{II} &= f(x) \\int_{-1}^1  \\frac{\\sin\\left(\\left(N+\\frac{1}{2}\\right)\\pi(y-x)\\right)}{2\\sin\\left(\\frac{\\pi(y-x)}{2}\\right)} \\, dy \\\\\n",
    "                \\\\\n",
    "                &= f(x) \\left[\\int_{-1}^1 \\frac{1}{2} + \\sum_{k=1}^N \\cos(k\\pi(y-x))\\right] \\, dy \\\\\n",
    "                \\\\\n",
    "                &= f(x) \\underbrace{\\int_{-1}^1 \\frac{1}{2}\\, dy}_{=1} + f(x) \\underbrace{\\int_{-1}^1 \\sum_{k=1}^N \\cos(k\\pi(y-x))\\, dy}_{=0} \\\\\n",
    "                &= f(x).\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Thus, the game has simplified to studying the limit of the integral denoted by $\\mathbf{I}$ above as $N\\to\\infty$. If we can show that the limit of this integral is zero as $N\\to\\infty$, then we will have proven that $S_N(x)\\to f(x)$ at this point of continuity $x\\in [-1,1]$. \n",
    "\n",
    "To simplify things, let $g(y)=f(y)-f(x)$ where $x$ is the fixed point of continuity under consideration and $y$ is free to vary in $[-1,1]$. Since $f$ is assumed continuous at $x$, then $g$ is continuous at $x$ and $g(x)=0$. Since $f$ is assumed piecewise differentiable on $[-1,1]$, then so is $g$. Now, we rewrite $\\mathbf{I}$ as\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\mathbf{I} &= \\int_{-1}^1  \\frac{\\sin\\left(\\left(N+\\frac{1}{2}\\right)\\pi(y-x)\\right)}{2\\sin\\left(\\frac{\\pi(y-x)}{2}\\right)} g(y)\\, dy \\\\\n",
    "               \\\\\n",
    "               &= \\int_{-1}^1  \\sin\\left(\\left(N+\\frac{1}{2}\\right)\\pi(y-x)\\right)\\frac{g(y)}{2\\sin\\left(\\frac{\\pi(y-x)}{2}\\right)}\\, dy\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd204973-53a2-4083-bd35-635538e70a62",
   "metadata": {},
   "source": [
    "**Stream of Consciousness.** \n",
    "\n",
    "We therefore view $\\mathbf{I}$ as defining a type of Fourier coefficient of $\\frac{g(y)}{2\\sin\\left(\\frac{\\pi(y-x)}{2}\\right)}$ and wish to use Lemma 3.2.1 (more precisely the remark given after the outline of its proof) to prove this converges to zero as $N\\to\\infty$. To do so, we need to first establish that this ratio defines a piecewise-continuous function.\n",
    "\n",
    "At $y=x$, the function $\\frac{g(y)}{2\\sin\\left(\\frac{\\pi(y-x)}{2}\\right)}$ evaluates to $\\frac{0}{0}$, but the denominator is nonzero for any other $y\\in[-1,1]$ since $x\\in(-1,1)$ implies $|\\pi(y-x)/2| < \\pi$. We therefore have that this is a piecewise continuous function everywhere except possibly at $y=x$ where we need to establish that the one-sided limits exist. Conveniently, we can apply [L'Hôpital's rule](https://en.wikipedia.org/wiki/L%27H%C3%B4pital%27s_rule) to conclude the one-sided limits of the derivative exist at this point since the derivative of the denominator is a cosine function that is non-zero at $y=x$.\n",
    "This establishes that $\\frac{g(y)}{2\\sin\\left(\\frac{\\pi(y-x)}{2}\\right)}$ is indeed a piecewise-continuously differentiable function. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b933c992-917f-4bf7-9468-6219192ae17b",
   "metadata": {},
   "source": [
    "We have proven the following result.\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "#### Theorem 3.3.1: Pointwise Convergence of Fourier Series, Part I (The Best of Times)\n",
    "\n",
    "Let $f$ be a piecewise-continuously differentiable function on $[-1,1]$ and suppose $x\\in (-1,1)$ is a point of continuity for $f$, then the Fourier series converges to $f(x)$ at $x$.\n",
    "\n",
    "---\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd32277f-ec44-40d8-a17e-60cda7298fe1",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### Section 3.3.5: Convergence of Fourier Series (Part II: Begin Again)\n",
    "---\n",
    "\n",
    "What happens if $x\\in(-1,1)$ and $f$ has a jump discontinuity at this $x$?\n",
    "\n",
    "Do we begin all over again? NOOOOO! We just get clever.\n",
    "\n",
    "First of all, we recognize that if $f$ is replaced by its $2$-periodic continuation from $[-1,1]$ to $\\mathbb{R}$ and we redefine the integral for $S_N(x)$ over any interval of length $2$, then the answer will be the same. So, we consider the integral over $[x-1, x+1]$.\n",
    "\n",
    "Second, we break up the integral as the sum over two intervals $J^- = (x-1, x)$ and $J^+ = (x, x+1)$ and (pun intended) the **answer lies within** as before where we write\n",
    "\n",
    "$$\n",
    "    S_N(x) = S_N(x^-) + S_N(x^+)\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "    S_N(x^-) := \\int_{x-1}^x  \\frac{\\sin\\left(\\left(N+\\frac{1}{2}\\right)\\pi(y-x)\\right)}{2\\sin\\left(\\frac{\\pi(y-x)}{2}\\right)} (f(y)-f(x^-))\\, dy + \\int_{x-1}^x  \\frac{\\sin\\left(\\left(N+\\frac{1}{2}\\right)\\pi(y-x)\\right)}{2\\sin\\left(\\frac{\\pi(y-x)}{2}\\right)} f(x^-)\\, dy\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "    S_N(x^+) := \\int_{x}^{x+1}  \\frac{\\sin\\left(\\left(N+\\frac{1}{2}\\right)\\pi(y-x)\\right)}{2\\sin\\left(\\frac{\\pi(y-x)}{2}\\right)} (f(y)-f(x^+))\\, dy + \\int_{x}^{x+1}  \\frac{\\sin\\left(\\left(N+\\frac{1}{2}\\right)\\pi(y-x)\\right)}{2\\sin\\left(\\frac{\\pi(y-x)}{2}\\right)} f(x^+)\\, dy.\n",
    "$$\n",
    "\n",
    "In the above integrals, $f(x^-):=\\lim_{y\\uparrow x} f(y)$ and $f(x^+):=\\lim_{y\\downarrow x} f(y)$.\n",
    "\n",
    "As in the prior case, Lemma 3.2.1 implies that the first two integrals involved in $S_N(x^-)$ and $S_N(x^+)$ have limits of zero as $N\\to\\infty$. Also, as in the prior case, we can simply factor out the $f(x^-)$ and $f(x^+)$, respectively, in the second integrals in $S_N(x^-)$ and $S_N(x^+)$, respectively. Unlike the prior case, these integrals are now only equal to $1/2$ instead of $1$. From this, we conclude that\n",
    "\n",
    "$$\n",
    "    S_N(x)\\to \\frac{1}{2} \\left(f(x^-)+f(x^+)\\right), \\ \\text{ as } \\ N\\to\\infty.\n",
    "$$\n",
    "\n",
    "In other words, at points of a jump discontinuity, the Fourier series converges to the \"average\" value of $f(x)$ at this point as defined by the average value of its one-sided limits.\n",
    "\n",
    "The technique above where we shift the integrals and utilize the $2$-periodic extension of $f$ can also be used to show that \n",
    "\n",
    "$$\n",
    "    S_N(\\pm 1) \\to \\frac{1}{2} \\left(f(-1^+)+f(1^-)\\right), \\ \\text{ as } N\\to\\infty.\n",
    "$$\n",
    "\n",
    "In other words, $S_N(-1)$ and $S_N(1)$ converge to the average values of the one-sided limits of $f$ at the endpoints of the interval $[-1,1]$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b6373d-b8f3-4b15-8976-935842c689e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "This **illumination theory** is summarized in the following result.\n",
    "\n",
    "---\n",
    "#### Theorem 3.3.2: Pointwise Convergence of Fourier Series, Part II (A Nightmare to Remember)\n",
    "\n",
    "Let $f$ be a piecewise-continuously differentiable function on $[-1,1]$. Then, the Fourier series converges to\n",
    "\n",
    "(a) $f(x)$ if $x\\in(-1,1)$ and $f$ is continuous at $x$; \n",
    "\n",
    "(b) $\\frac{1}{2} \\left(f(x^-)+f(x^+)\\right)$ if $x\\in(-1,1)$ and $f$ is discontinuous at $x$; \n",
    "\n",
    "(c) $\\frac{1}{2} \\left(f(-1^+) + f(1^-)\\right)$ if $x=-1$ or $x=1$.\n",
    "\n",
    "---\n",
    "<br><br>\n",
    "\n",
    "**Remarks:**\n",
    "\n",
    "- Theorem 3.3.2(b) and Theorem 3.3.2(c) mathematically describe what is known as [***Gibbs phenomenon***](https://en.wikipedia.org/wiki/Gibbs_phenomenon).\n",
    "\n",
    "- The convergence of Theorem 3.3.2(a) (which is just a restatement of Theorem 3.3.1) and of Theorem 3.3.2(b) and Theorem 3.3.2(c) are *all* pointwise. But, it is possible to prove uniform convergence on sub-intervals $[a,b]$ that do not contain any jump discontinuities of the 2-periodic extension of $f$.\n",
    "\n",
    "- We still have not addressed convergence when $f$ is *only* piecwise-continuous. Ironically enough, we need to consider *smoother* $f$ before we consider *rougher* $f$ (i.e., $f$ that are *only* piecewise-continuous)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e3ec49-3bed-4092-920d-c49f0f5f0636",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: x\n",
    "\n",
    "x_end_pts = np.array([-1, 1])\n",
    "\n",
    "Ns = [5, 10, 20, 40]\n",
    "\n",
    "S_Ns = np.zeros( (2, len(Ns)) )\n",
    "for i in range(len(Ns)):\n",
    "    S_Ns[:,i] = S_N(f, Ns[i], x_end_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95124b15-2977-4b65-9e2d-c654c310ff13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(f(x_end_pts)))\n",
    "print('-'*50)\n",
    "print(S_Ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc5baaa-91be-436a-896e-c1afd8a81f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: x**3-2*x**2\n",
    "\n",
    "x_end_pts = np.array([-1, 1])\n",
    "\n",
    "Ns = [5, 10, 20, 40]\n",
    "\n",
    "S_Ns = np.zeros( (2, len(Ns)) )\n",
    "for i in range(len(Ns)):\n",
    "    S_Ns[:,i] = S_N(f, Ns[i], x_end_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dac16e-7a9e-4a4c-bdd9-bda9d08da06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(f(x_end_pts)))\n",
    "print('-'*50)\n",
    "print(S_Ns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09537910-64a9-4ed3-ad16-36a2c430e279",
   "metadata": {},
   "source": [
    "---\n",
    "### Section 3.3.6: Uniform Convergence (Caught in a Web)\n",
    "---\n",
    "\n",
    "Suppose now that $f$ is actually continous and periodic with $f(-1)=f(1)$ so that its 2-periodic extension is also continuous and further assume that $f'$ is piecewise continuous on $[-1,1]$. \n",
    "\n",
    "In this case, Theorem 3.2.2 implies that for all $x\\in[-1,1]$, \n",
    "\n",
    "$$\n",
    "    f(x) = \\lim_{N\\to\\infty} S_N(x) = \\frac{a_0}{2} + \\sum_{k=1}^\\infty \\left(a_k\\cos(k\\pi x) + b_k\\sin(k\\pi x)\\right).\n",
    "$$\n",
    "\n",
    "This implies that for each $x\\in[-1,1]$, \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    |f(x)-S_N(x)| &= \\left|  \\sum_{k=N+1}^\\infty \\left(a_k\\cos(k\\pi x) + b_k\\sin(k\\pi x)\\right)\\right| \\\\\n",
    "                  \\\\\n",
    "                  &\\leq \\sum_{k=N+1}^\\infty \\left(|a_k| + |b_k|\\right).\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Taking the supremum over $x\\in[-1,1]$ on both sides of the inequality (and observing that the right-hand side of the inequality is independent of $x$) gives\n",
    "\n",
    "$$\n",
    "    \\| f-S_N \\|_\\infty \\leq \\sum_{k=N+1}^\\infty \\left(|a_k| + |b_k|\\right).\n",
    "$$\n",
    "\n",
    "If we can show that the sum is finite, then for sufficiently large $N$, we can make this sum as small as we need to conclude that $S_N\\to f$ uniformly on $[-1,1]$. We do this by relating this sum to a Fourier series expansion of $f'$.\n",
    "\n",
    "By assumption of $f'$ being piecewise continuous, it has a Fourier series expansion that we denote by\n",
    "\n",
    "$$\n",
    "    \\frac{\\alpha_0}{2} + \\sum_{k=1}^\\infty \\left(\\alpha_k\\cos(k\\pi x) + \\beta_k\\sin(k\\pi x)\\right).\n",
    "$$\n",
    "\n",
    "By assumption of $f(-1)=f(1)$, so we have that $\\alpha_0=0$. Utilizing [Bessel's inequality](https://en.wikipedia.org/wiki/Bessel%27s_inequality) (which we can do since for $k\\in\\mathbb{N}$, the cosine and sine terms are an orthonormal sequence in $L^2([-1,1])$), we have that\n",
    "\n",
    "$$\n",
    "    \\sum_{k=1}^\\infty \\left(\\alpha_k^2 + \\beta_k^2 \\right) \\leq \\int_{-1}^1 (f'(x))^2\\, dx <\\infty.\n",
    "$$\n",
    "\n",
    "At the same time, an integration by parts shows that $\\alpha_k=k\\pi b_k$ and $\\beta_k=-k\\pi a_k$, so for any integer $N$, we have that\n",
    "\n",
    "$$\n",
    "    \\sum_{k=1}^N \\left(|a_k| + |b_k|\\right) = \\frac{1}{\\pi} \\sum_{k=1}^N \\frac{1}{k} \\left( |\\alpha_k| + |\\beta_k| \\right).\n",
    "$$\n",
    "\n",
    "Now, a [Cauchy-Schwarz inequality](https://en.wikipedia.org/wiki/Cauchy%E2%80%93Schwarz_inequality) implies that\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\sum_{k=1}^N \\frac{1}{k}|a_k| &\\leq \\left(\\sum_{k=1}^N \\frac{1}{k^2}\\right)^{1/2}\\left(\\sum_{k=1}^N \\alpha_k^2\\right)^{1/2} \\\\\n",
    "                                  \\\\\n",
    "                                  &\\leq \\left(\\sum_{k=1}^N \\frac{1}{k^2}\\right)^{1/2}\\left(\\sum_{k=1}^N \\alpha_k^2+\\beta_k^2\\right)^{1/2}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Notice we get the same inequality for $\\sum_{k=1}^N \\frac{1}{k}|b_k|$. This implies that\n",
    "\n",
    "$$\n",
    "    \\sum_{k=1}^N \\left(|a_k| + |b_k|\\right) \\leq \\frac{2}{\\pi} \\left(\\sum_{k=1}^N \\frac{1}{k^2}\\right)^{1/2}\\left(\\sum_{k=1}^N \\alpha_k^2+\\beta_k^2\\right)^{1/2}.\n",
    "$$\n",
    "\n",
    "Since this bound holds for all $N$ and the terms involved are all nonnegative, we have that\n",
    "\n",
    "$$\n",
    "    \\sum_{k=1}^\\infty \\left(|a_k| + |b_k|\\right) \\leq \\frac{2}{\\pi} \\left(\\sum_{k=1}^\\infty \\frac{1}{k^2}\\right)^{1/2}\\left(\\sum_{k=1}^\\infty \\alpha_k^2+\\beta_k^2\\right)^{1/2} \n",
    "$$\n",
    "\n",
    "where we understand this may mean $\\infty\\leq \\infty$, which is perfectly acceptable. However, we will in fact show that this implies the sum on the left-hand side of the inequality is finite.\n",
    "\n",
    "From a [$p$-series test](https://en.wikipedia.org/wiki/Convergence_tests#p-series_test), \n",
    "\n",
    "$$\n",
    "    \\left(\\sum_{k=1}^\\infty \\frac{1}{k^2}\\right)^{1/2}<\\infty.\n",
    "$$\n",
    "\n",
    "Using the previous bound from Bessel's inequality, \n",
    "\n",
    "$$\n",
    "    \\left(\\sum_{k=1}^\\infty \\alpha_k^2+\\beta_k^2\\right)^{1/2} \\leq \\left(\\int_{-1}^1 (f'(x))^2\\, dx\\right)^{1/2} < \\infty.\n",
    "$$\n",
    "\n",
    "Putting this all together, we have that\n",
    "\n",
    "$$\n",
    "    \\sum_{k=1}^\\infty \\left(|a_k| + |b_k|\\right) <\\infty.\n",
    "$$\n",
    "\n",
    "The uniform convergence is thus proven."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fba0f4-f981-4728-89f8-0301b88f1484",
   "metadata": {},
   "source": [
    "---\n",
    "#### Theorem 3.3.3: Uniform Convergence of Fourier Series (Just Let me Breathe)\n",
    "\n",
    "Let $f$ be continous and periodic with $f(-1)=f(1)$ so that its 2-periodic extension is also continuous and further assume that $f'$ is piecewise continuous on $[-1,1]$. Then, the Fourier series converges uniformly to $f$ on $[-1,1]$ and the Fourier coefficients converge to zero at a rate of $\\mathcal{O}(1/k)$. \n",
    "\n",
    "---\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50528ad-b2f8-4ce1-b235-3f99bd9dc836",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: np.heaviside(-x, 0)*(1+x) + np.heaviside(x, 1)*(1-x)\n",
    "\n",
    "%matplotlib widget\n",
    "plt.figure(5)\n",
    "\n",
    "x_domain = np.linspace(-1, 1, 100)\n",
    "\n",
    "plt.plot(x_domain, f(x_domain), 'b', lw=2, label='f(x) on [-1,1]')\n",
    "\n",
    "Ns = [2, 4, 8, 16, 32]\n",
    "\n",
    "for i in range(len(Ns)):\n",
    "    plt.plot(x_domain, S_N(f, Ns[i], x_domain), ls='--', label='$S_{}' + str(Ns[i]) + '}(x)$')\n",
    "\n",
    "plt.legend(fontsize=12, shadow=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80aa1620-50db-44ba-854d-f763285b3e0b",
   "metadata": {},
   "source": [
    "---\n",
    "### Section 3.3.7: Mean Square Convergence (A New Beginning)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e34710-dba8-40cf-8996-014945c5699a",
   "metadata": {},
   "source": [
    "We can now weaken the smoothness of $f$ by just assuming it is piecewise-continuous to get the following result.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "#### Theorem 3.3.4: $L^2$ Convergence of Fourier Series (Cover My Eyes)\n",
    "\n",
    "Let $f$ be a piecewise-continuous function on $[-1,1]$. Then, the Fourier series converges to $f$ in the $L^2$ (i.e., mean square) sense. \n",
    "\n",
    "---\n",
    "\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "***Idea of proof of Theorem 3.3.4:***\n",
    "\n",
    "1. Let $f$ refer to its 2-periodic extension on $\\mathbb{R}$ and for each $x\\in [-1,1]$ and $\\delta>0$, define $f_\\delta(x):=\\frac{1}{2\\delta} \\int_{x-\\delta}^{x+\\delta} f(y)\\, dy$, which is the average value of $f$ on $[x-\\delta, x+\\delta]$. \n",
    "\n",
    "2. Recognize that $f_\\delta$ is 2-periodic (because $f$ is recognized as its 2-periodic extension), and by the fundamental theorem of calculus $f_\\delta'$ is piecewise continuous and $f_\\delta$ itself is continuous. \n",
    "\n",
    "3. Recognize that Theorem 3.3.3 applies to $f_\\delta$.\n",
    "\n",
    "4. Letting $S_N(x)$ denote the Fourier partial sum of $f$ and $S_{N,\\delta}(x)$ denote the Fourier partial sum of $f_\\delta$, write\n",
    "\n",
    "$$\n",
    "    S_N(x) - f(x) = \\underbrace{S_N(x)-S_{N,\\delta}(x)}_{\\mathbf{I}} + \\underbrace{S_{N,\\delta}(x)-f_\\delta(x)}_{\\mathbf{II}} + \\underbrace{f_\\delta(x)-f(x)}_{\\mathbf{III}}.\n",
    "$$\n",
    "\n",
    "5. Apply the $L^2$ norm (i.e., mean square error) and a triangle inequality to get a bound on the $L^2$ norm of $S_n(x)-f(x)$ in terms of the sums of the $L^2$ norms of terms $\\mathbf{I}$, $\\mathbf{II}$, and $\\mathbf{III}$.\n",
    "\n",
    "6. Use different arguments to prove that these $L^2$ norms of $\\mathbf{I}$, $\\mathbf{II}$, and $\\mathbf{III}$ can all be made small to finish the proof.\n",
    "\n",
    "---\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b88d020-198b-4e10-9761-37f4b828eeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_x(x):\n",
    "    if int(x)%2 == 0:\n",
    "        return x-int(x)\n",
    "    else:\n",
    "        return -1+np.abs(x)-int(np.abs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75e9edc-24b1-4df4-8b8e-0b5c48cbceaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_2_periodic(f, x):\n",
    "    return f(translate_x(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efc6be9-513c-463e-9ddc-d8167f90a66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_delta(f, delta, x):\n",
    "    v = np.zeros(len(x))\n",
    "    f_2 = lambda x: f_2_periodic(f, x)\n",
    "    for i in range(len(x)):\n",
    "        v[i] = 1/(2*delta)*quad(f_2, x[i]-delta, x[i]+delta)[0]\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fb0352-e3e9-435c-b2a8-7e78185e5c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: np.heaviside(-x, 0)*(1+x) + np.heaviside(x, 1)*(1-x)\n",
    "\n",
    "%matplotlib widget\n",
    "plt.figure(6)\n",
    "\n",
    "x_domain = np.linspace(-1, 1, 100)\n",
    "\n",
    "deltas = [0.2, 0.1, 0.05, 0.025]\n",
    "\n",
    "x_extension = np.linspace(-3, 3, 300)\n",
    "\n",
    "for i in range(len(deltas)):\n",
    "    plt.plot(x_extension, f_delta(f, deltas[i], x_extension), ls='--', label='$f_{' + str(deltas[i]) + '}(x)$')\n",
    "\n",
    "plt.legend(fontsize=12, shadow=True)\n",
    "\n",
    "plt.plot(x_domain, f(x_domain), 'b', lw=2, label='f(x) on [-1,1]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e07344f-eec7-4224-a6b1-932fa5605fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: x**3-2*x**2\n",
    "\n",
    "%matplotlib widget\n",
    "plt.figure(7)\n",
    "\n",
    "x_domain = np.linspace(-1, 1, 100)\n",
    "\n",
    "deltas = [0.2, 0.1, 0.05, 0.025, 0.01, 0.005]\n",
    "\n",
    "x_extension = np.linspace(-3, 3, 300)\n",
    "\n",
    "for i in range(len(deltas)):\n",
    "    plt.plot(x_extension, f_delta(f, deltas[i], x_extension), ls='--', label='$f_{' + str(deltas[i]) + '}(x)$')\n",
    "\n",
    "plt.legend(fontsize=12, shadow=True)\n",
    "\n",
    "plt.plot(x_domain, f(x_domain), 'b', lw=2, label='f(x) on [-1,1]')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b39c7b6-96aa-425d-824d-1e5932c0a310",
   "metadata": {},
   "source": [
    "---\n",
    "### Section 3.3.8: Rates of Convergence for Smooth Functions (Build Me Up, Break Me Down)\n",
    "---\n",
    "\n",
    "<mark>**This subsection is unfinished work. I provide the big takeaways. This will be finished the next time I teach the course.**</mark>\n",
    "\n",
    "The main takeaways of this subsection are that\n",
    "\n",
    "- the smoother $f$ is, the faster the associated Fourier coefficients of $f$ decay to zero, and\n",
    "\n",
    "- the faster the Fourier coefficients decay to zero, the smoother the function $f$ must be that is the limit of the associated Fourier series.\n",
    "\n",
    "The proofs use induction based on the argument shown in Section 3.3.6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8e6f4b-3ff0-4c41-801a-125f93a0a0d4",
   "metadata": {},
   "source": [
    "**Some notation**\n",
    "\n",
    "- Let $\\mathcal{C}_p^m((-1,1))$ denote the functions that are $m$-times continuously differentiable on $(-1,1)$ and 2-periodic so that $f^{(j)}(-1)=f^{(j)}(1)$ for $j=0,1,\\ldots, m$ for all $f\\in\\mathcal{C}_p^m((1,1))$.\n",
    "\n",
    "- Let $\\widehat{\\mathcal{C}_p^m}((-1,1))$ denote the functions that are in $\\mathcal{C}_p^{m-1}((-1,1))$ with $f^{(m)}$ being piecewise continuous.\n",
    "\n",
    "The goal is to generalize the results from Section 3.3.6 where we only assumed $f'$ was piecewise continuous."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977cb0c2-3a25-4863-8587-a187511b15ac",
   "metadata": {},
   "source": [
    "---\n",
    "#### An inductive argument (the basic idea)\n",
    "---\n",
    "\n",
    "Following the analysis of Section 3.3.6, we treat Theorem 3.3.3 as the base case for $f\\in\\widehat{\\mathcal{C}_p^1}((-1,1))$.\n",
    "\n",
    "Assume for the first $m$ cases that if $f\\in\\widehat{\\mathcal{C}_p^m}((-1,1))$, then the Fourier series converges uniformly to $f$ on $[-1,1]$ and the Fourier coefficients converge to zero at a rate of $\\mathcal{O}(1/k^m)$.\n",
    "\n",
    "For the $m+1$ case, if $f\\in\\widehat{\\mathcal{C}_p^{m+1}}((-1,1))$, then $f'\\in\\widehat{\\mathcal{C}_p^{m}}((-1,1))$, and the relationship of $\\alpha_k=k\\pi b_k$ and $\\beta_k=-k\\pi a_k$ (where $\\alpha_k$ and $\\beta_k$ denote the Fourier coefficients of $f'$ while $a_k$ and $b_k$ denote the Fourier coefficients of $f$) gives the result that the Fourier series converges uniformly to $f$ on $[-1,1]$ and that the Fourier coefficients converge to zero at a rate of $\\mathcal{O}(1/k)\\mathcal{O}(1/k^m)=\\mathcal{O}(1/k^{m+1})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5707f6-474c-4453-874a-4d5e1c6e3416",
   "metadata": {},
   "outputs": [],
   "source": [
    "### To-Do: Examples showing the ROC of Fourier coefficients for smooth functions\n",
    "### Example 1: f=abs(x) which is \\widehat{C}_p^1 because f' is piecewise continuous\n",
    "### Example 2: f=x^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd1ff26-a8aa-4a29-8c17-c7573be75f68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b3a83f-49f5-4ab3-920e-214c9c879935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "273436f5-8fb9-4ca1-83c7-99fec611ac7d",
   "metadata": {},
   "source": [
    "---\n",
    "#### Filling in some details\n",
    "---\n",
    "\n",
    "In the proof of Theorem 3.3.3, we utilized [Bessel's inequality](https://en.wikipedia.org/wiki/Bessel%27s_inequality) to state that since the cosine and sine terms are an orthonormal sequence in $L^2([-1,1])$), it follows that\n",
    "\n",
    "$$\n",
    "    \\sum_{k=1}^\\infty \\left(\\alpha_k^2 + \\beta_k^2 \\right) \\leq \\int_{-1}^1 (f'(x))^2\\, dx, \n",
    "$$\n",
    "\n",
    "where $\\alpha_k=k\\pi b_k$ and $\\beta_k=k\\pi a_k$ are the Fourier coefficients for $f'$ (where the $a_k$ and $b_k$ terms are the Fourier coefficients for $f$). The inequality is, in fact, an equality, for the reasons we discuss below.\n",
    "\n",
    "Recall that the Fourier series of $f'$ is given by\n",
    "\n",
    "$$\n",
    "    \\sum_{k=1}^\\infty \\left(\\alpha_k \\cos(k\\pi x) + \\beta_k\\sin(k\\pi x)\\right)\n",
    "$$\n",
    "\n",
    "where the constant term is zero because of the assumed periodicity of the function $f$ as was discussed in the proof of Theorem 3.3.3. Thus, if we consider piecewise continuous functions that are integrable with an antiderivative that is periodic on $[-1,1]$, then $\\{\\cos(k\\pi x), \\sin(k\\pi x)\\}_{k\\in\\mathbb{N}}$ forms an *orthonormal basis* for such functions. In this case, Bessel's inequality actually turns into [Parseval's identity](https://en.wikipedia.org/wiki/Parseval%27s_identity) (the version that is the generalization of the Pythagorean theorem), i.e., \n",
    "\n",
    "$$\n",
    "    \\sum_{k=1}^\\infty \\left(\\alpha_k^2 + \\beta_k^2 \\right) = \\int_{-1}^1 (f'(x))^2\\, dx.\n",
    "$$\n",
    "\n",
    "Since the right-hand side is exactly equal to $\\|f\\|_{L^2((-1,1))}^2$, substituting $\\alpha_k=k\\pi b_k$ and $\\beta_k=k\\pi a_k$ into the left-hand side yields\n",
    "\n",
    "$$\n",
    "    \\sum_{k=1}^\\infty k^2\\left(a_k^2 + b_k^2\\right) = \\pi^{-2} \\|f'\\|_{L^2((-1,1))}^2.\n",
    "$$\n",
    "\n",
    "We can proceed by induction to show that for any $m\\in\\mathbb{N}$, \n",
    "\n",
    "$$\n",
    "    \\sum_{k=1}^\\infty k^{2m}\\left(a_k^2 + b_k^2\\right) =\\pi^{-2m}\\| f^{(m)}\\|_{L^2((-1,1))}^2.\n",
    "$$\n",
    "\n",
    "Since the right-hand side is always less than infinity whenever $f^{(m)}$ is piecewise-continuous (which ensures this derivative is square integrable), this establishes that $a_k$ and $b_k$ must decay to zero faster than $1/k^{m}$ in order for the series to be finite summable. \n",
    "\n",
    "This proves the first part of the main result for this subsection, which we state below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf217630-27b0-47cb-8027-9fc9e2bbdf7e",
   "metadata": {},
   "source": [
    "---\n",
    "#### Theorem 3.3.5: Smoothness and Rates of Decay of Coefficients\n",
    "\n",
    "Suppose $m\\in\\mathbb{N}$. Then,\n",
    "\n",
    "- $\\sum_{k=1}^\\infty k^{2m}\\left(a_k^2 + b_k^2\\right) =\\pi^{-2m}\\| f^{(m)}\\|_{L^2((-1,1))}^2$, where $a_k$ and $b_k$ are the Fourier coefficients of $f\\in\\widehat{\\mathcal{C}_p^m}((-1,1))$, and\n",
    "\n",
    "- if $(a_k),(b_k)\\subset\\mathbb{R}$ such that $\\sum_{k=1}^\\infty k^{2m}\\left(a_k^2 + b_k^2\\right)<\\infty$, then\n",
    "<br>\n",
    "$$\n",
    "    S_N(x) = \\frac{a_0}{2} + \\sum_{k=1}^N \\left(a_k\\cos(k\\pi x) + b_k\\sin(k\\pi x)\\right)\n",
    "$$\n",
    "<br>\n",
    "defines a sequence of functions for each $N\\in\\mathbb{N}$ such that $S_N\\to f\\in\\widehat{\\mathcal{C}_p^m}((-1,1))$ uniformly. Moreover, $S_N^{(j)}\\to f^{(j)}$ uniformly for $0\\leq j\\leq m-1$, and the Fourier series of $f$ is given by \n",
    "<br>\n",
    "$$\n",
    "    \\frac{a_0}{2} + \\sum_{k=1}^\\infty \\left(a_k\\cos(k\\pi x) + b_k\\sin(k\\pi x)\\right)\n",
    "$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4d44b9-573e-4502-a28a-b9fffb47cf68",
   "metadata": {},
   "source": [
    "To prove the second part of Theorem 3.3.5, we also use induction. \n",
    "\n",
    "To establish the base case for $m=1$, let $(a_k), (b_k)\\subset\\mathbb{R}$ such that $\\sum_{k=1}^\\infty k^2 (a_k^2 + b_k^2)<\\infty$ and let \n",
    "\n",
    "$$\n",
    "    S_N(x) = \\frac{a_0}{2} + \\sum_{k=1}^N \\left(a_k\\cos(k\\pi x) + b_k\\sin(k\\pi x)\\right).\n",
    "$$\n",
    "\n",
    "The goal is to show that there exists $f\\in\\widehat{\\mathcal{C}_p^1}((-1,1))$ (i.e., a periodic differentiable function with a piecewise continuous derivative) such that $S_N\\to f$ uniformly.\n",
    "\n",
    "To do this, we exploit the completeness of the real numbers (where Cauchy sequences are equivalent to convergent sequences) and a result from elementary analysis that states a uniformly Cauchy sequence of continuous real-valued functions converges to a continuous real-valued function.\n",
    "\n",
    "First, let $\\epsilon>0$ and $x\\in[-1,1]$ and assume $M>N$ so that\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    |S_M(x)-S_N(x)| &\\leq \\sum_{k=N+1}^M \\left(|a_k| + |b_k|\\right) \\\\ \\\\\n",
    "                    &= \\sum_{k=N+1}^M \\frac{1}{k}\\left(k\\left(|a_k| + |b_k|\\right)\\right).\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "As in the proof of Theorem 3.3.3, we utilize the [Cauchy-Schwarz inequality](https://en.wikipedia.org/wiki/Cauchy%E2%80%93Schwarz_inequality) to obtain\n",
    "\n",
    "$$\n",
    "    |S_M(x) - S_N(x)| \\leq \\left(\\sum_{k=N+1}^M \\frac{1}{k^2}\\right)^{1/2} \\left(\\sum_{k=N+1}^M k^2\\left(a_k^2 + b_k^2\\right)\\right)^{1/2}.\n",
    "$$\n",
    "\n",
    "Since $\\sum_{k=1}^\\infty \\frac{1}{k^2}<\\infty$ and $\\sum_{k=N+1}^M k^2\\left(a_k^2 + b_k^2\\right)<\\infty$ by assumption, there exists $K$ such that $M>N\\geq K$ implies \n",
    "\n",
    "$$\n",
    "    \\left(\\sum_{k=N+1}^M \\frac{1}{k^2}\\right)^{1/2} \\left(\\sum_{k=N+1}^M k^2\\left(a_k^2 + b_k^2\\right)\\right)^{1/2} < \\epsilon.\n",
    "$$\n",
    "\n",
    "Moreover, this choice of $K$ is determined only in terms of summations that are independent of $x$, thus\n",
    "\n",
    "$$\n",
    "    \\|S_M(x)-S_N(x)\\|_\\infty = \\sup_{x\\in(-1,1)} |S_M(x) - S_N(x)| < \\epsilon\n",
    "$$\n",
    "\n",
    "for all $M>N\\geq K$. This proves that $(S_N)$ defines a uniformly Cauchy sequence of continuous real-valued functions. The base case follows. The remaining details for applying the inductive hypothesis to finish the proof are left to the interested reader as they just require re-using the above argument with appropriate modifications to notation involving the derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd46d968-13b0-4d6a-8e79-4de5ba0d124a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### To-Do: Examples showing controlling decay of Fourier coefficients for a_k and b_k \n",
    "### results in smooth functions.\n",
    "### Just set $a_k$ and $b_k$ to $1/k^m$ for choices of m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fa00a1-dc96-4bc0-a23b-d68e09dfcfaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db36fbdf-05c6-467e-adc1-69e73d78247e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c4cf3a4-85d4-4718-9b04-565374c3e2f7",
   "metadata": {},
   "source": [
    "---\n",
    "### Section 3.3.9: \"Half\" Fourier Series and Solutions to the Heat Equation (Invisible Monster)\n",
    "---\n",
    "\n",
    "First note that if $f$ is an even function (so $f(-x)=f(x)$), then it is straightforward to show that $b_k=0$ for all $k\\in\\mathbb{N}$ in its full Fourier series expansion (i.e., all the coefficients for the sine terms are zero). Similarly, if $f$ is an odd function (so $f(-x)=-f(x)$), then $a_k=0$ for all $k\\in\\mathbb{N}\\cup\\{0\\}$ in its full Fourier series expansion (i.e., all the coefficients for the cosine terms are zero).\n",
    "\n",
    "Consider some function $f$ on $[0,1]$ (or, more generally, $[0,\\ell]$ for some $\\ell>0$). Below, we consider the Fourier sine and Fourier cosine series expansions resulting from an odd or even extension of $f$, respectively, to $[-1,1]$ (or, more generally, $[-\\ell,\\ell]$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9266df-3a31-420f-ab3a-d597082178eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### To-Do: Create functions defining even and odd extensions of f and then the computation of their Fourier coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c759e87-a90b-4f57-a309-0b5ca964c10c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7870d71c-dfd5-489d-a47b-9959bf3b2f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd69c7ee-0a6a-4190-ba50-34ca4aa3f706",
   "metadata": {},
   "source": [
    "---\n",
    "#### An even extension and Fourier cosine series (The Path That Divides)\n",
    "---\n",
    "\n",
    "If we extend $f$ from $[0,1]$ to an even function on $[-1,1]$ and compute the Fourier series expansion, then $b_k=0$ for all $k\\in\\mathbb{N}$ resulting in\n",
    "\n",
    "$$\n",
    "    f(x) = \\frac{a_0}{2} + \\sum_{k=1}^\\infty a_k \\cos\\left(k\\pi x\\right). \n",
    "$$\n",
    "\n",
    "Here, we are slightly abusing notation by using the same $f$ to denote the even extension of the original $f$ from $[0,1]$ to $[-1,1]$.\n",
    "\n",
    "Of course, since $f$ is now, as a matter of the adopted perspective, considered an even function, the integrals defining $a_k$, for each $k\\in\\mathbb{N}\\cup\\{0\\}$, are for an even function (the product of two even functions is an even function), so they have the property that\n",
    "\n",
    "$$\n",
    "    a_k = \\int_{-1}^1 f(x)\\cos (k\\pi x)\\, dx = 2\\int_0^1 f(x)\\cos(k\\pi x).\n",
    "$$\n",
    "\n",
    "- In the more general case where $\\ell>0$ and $\\ell\\neq 1$, the multiplicative factor for the integral becomes $2/\\ell$, the limits of integration are from $0$ to $\\ell$, and the argument for the cosine function is scaled by $1/\\ell$. In other words, this reduces exactly to the formula seen in [Section 3.2](Chp3Sec2.ipynb) for the Fourier coefficients associated with the homogeneous Neumann heat equation involving a Fourier cosine series expansion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5964e87c-f685-4b5f-8867-dfb6af9a3f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some examples showing how just the cosine terms involve \"half period\" cosines on [0,1] \n",
    "# even though there are only \"full period\" functions on [-1,1]. Compare the Fourier cosine\n",
    "# coefficients for a function like $f(x)=x$ on [0,1] to the Fourier cosine and sine coefficients\n",
    "# on $[-1,1]$. Note how the half-period cosines take the place of the missing sine functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8080299e-de7f-48c9-94fb-de1265d2fe82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38f59fb-fc89-4fef-8943-35926c8ce58c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b425ca46-0e16-4b11-811e-057df3eb0e75",
   "metadata": {},
   "source": [
    "---\n",
    "#### An odd extension and Fourier sine series (The Mirror)\n",
    "---\n",
    "\n",
    "If we extend $f$ from $[0,1]$ to an odd function on $[-1,1]$ and compute the Fourier series expansion, then $a_k=0$ for all $k\\in\\mathbb{N}\\cup\\{0\\}$ resulting in\n",
    "\n",
    "$$\n",
    "    f(x) = \\sum_{k=1}^\\infty b_k\\sin(k\\pi x).\n",
    "$$\n",
    "\n",
    "Again, we are slightly abusing notation by using the same $f$ to denote the odd extension of the original $f$ from $[0,1]$ to $[-1,1]$. Note that we may have to deal with the fact that the odd extension of $f$ is discontinuous at $x=0$ even if $f$ is continuous on $[0,1]$ (the odd extension will only be continuous if $f(0)=0$). Fortunately, the actual value of $f$ at $x=0$ is immaterial to the calculation of any integral of $f$ over a domain containing $x=0$.\n",
    "\n",
    "As above, we have that the integrals defining $b_k$ for each $k\\in\\mathbb{N}$ are for an even function (the product of two odd functions is an even function), so \n",
    "\n",
    "$$\n",
    "    b_k = \\int_{-1}^1 f(x)\\sin(k\\pi x)\\, dx = 2\\int_0^1 f(x)\\sin(k\\pi x).\n",
    "$$\n",
    "\n",
    "- In the more general case where $\\ell>0$ and $\\ell\\neq 1$, the multiplicative factor for the integral becomes $2/\\ell$, the limits of integration are from $0$ to $\\ell$, and the argument for the sine function is scaled by $1/\\ell$. In other words, this reduces exactly to the formula seen in [Section 3.2](Chp3Sec2.ipynb) for the Fourier coefficients associated with the homogeneous Dirichlet heat equation involving a Fourier sine series expansion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5a0fa6-51d0-4618-8cfd-a0c99abe5da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some examples showing how just the sine terms involve \"half period\" cosines on [0,1] \n",
    "# even though there are only \"full period\" functions on [-1,1]. Compare the Fourier sine coefficients\n",
    "# for a function like $f(x)=x^2$ on $[0,1]$ to the Fourier cosine and sine coefficients on $[-1,1]$.\n",
    "# Note how the \"half period\" sines are taking the place of the cosine terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d094e5-66f5-4af8-9b5d-6e5941bca475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59585dd-d430-42bf-a328-c5c681f68356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32494c89-9862-4a6c-ab36-67fced7c85a3",
   "metadata": {},
   "source": [
    "---\n",
    "### Section 3.3.10: No Longer Formal Solutions to the Heat Equation (At Wit's End)\n",
    "---\n",
    "\n",
    "For the homogeneous Dirichlet heat equation seen in [Section 3.2](Chp3Sec2.ipynb) with a spatial domain of $(0,\\ell)$, we first write $f$ as a Fourier sine series\n",
    "\n",
    "$$\n",
    "    f(x) = \\sum_{k=1}^\\infty c_k\\sin\\left(\\frac{k\\pi x}{\\ell}\\right), \n",
    "$$\n",
    "\n",
    "where we have reverted to the notation of $c_k$ for the coefficients since there are only sine terms in the expansion. \n",
    "\n",
    "The formal solution to the problem is then given as\n",
    "\n",
    "$$\n",
    "    u(x,t) = \\sum_{k=1}^\\infty c_k  \\exp\\left(-c\\frac{(k\\pi)^2}{\\ell^2} t\\right) \\sin\\left(\\frac{k\\pi x}{\\ell}\\right).\n",
    "$$\n",
    "\n",
    "<mark>***So far, all the theory of this section has justified our ability to write $f$ as a Fourier sine series. However, we have yet to justify why $u$ written in the form above is a valid solution to the homogeneous Dirichlet heat equation.***</mark>\n",
    "\n",
    "There are a few issues to address. Mainly, if $u$ is intended to be a \"classical\" solution, meaning it is \"smooth\" in both space and time so that all the necessary derivatives exist for the PDE to be satisfied pointwise as well as the BCs and IC, then we know from above that $f$ needs to satisfy some conditions in order to avoid Gibbs phenomena (see Theorem 3.3.2). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a298d9b-8528-401c-9ed6-7e7b4d8d17cb",
   "metadata": {},
   "source": [
    "---\n",
    "#### Compatibility conditions (The Shattered Fortress)\n",
    "---\n",
    "\n",
    "If $u(x,t)$ is continuous on $[0,\\ell]\\times[0,\\infty)$, then\n",
    "\n",
    "$$\n",
    "    u(0,0) = \\lim_{t\\downarrow 0} u(0,t) = \\lim_{t\\downarrow 0} 0 = 0.\n",
    "$$\n",
    "\n",
    "At the same time, \n",
    "\n",
    "$$\n",
    "    u(0,0) = f(0), \n",
    "$$\n",
    "\n",
    "which immediately implies\n",
    "\n",
    "$$\n",
    "    f(0) = 0.\n",
    "$$\n",
    "\n",
    "Similarly, we have that $f(1)=0$.\n",
    "\n",
    "Thus, if $u$ is a classical solution to the homogeneous Dirichlet heat equation, then the IC $f(x)$ must satisfy \n",
    "\n",
    "$$\n",
    "    \\underbrace{f(0)=f(1)=0}_\\text{Compatibility condition}.\n",
    "$$\n",
    "\n",
    "- Recall that in an activity within [Section 3.2](Chp3Sec2.ipynb) that a formal solution to the homogeneous Dirichlet heat equation is given for $f\\equiv 1$ with $\\ell=1$, which clearly does not satsify the compatibility condition above. Thus, there is no classical solution to the problem for this IC. How do we reconcile the existence of the formal solution with the clear evidence that there is no classical solution to the problem?\n",
    "\n",
    "> Author's note: The entire fixation with classical solutions, which we might as well call \"pointwise\" solutions to PDEs is almost entirely abandoned in modern PDE theory where we generally start by seeking to prove the existence (and of course uniqueness) of solutions in Sobolev spaces for which the notion of a pointwise value of a function is essentially meaningless. While most individuals would be more than satisfied to stop at proving existence and uniqueness of solutions (count me in that category), a subset of mathematicians with a high tolerance for pain take it further with proving regularity results (meaning smoothness results). Basically, in cases where the geometry of the domain is not truly awful and the parameters (i.e., coefficients in the PDE) and data (i.e., boundary/initial conditions and source terms) are \"not too rough\" (or perhaps \"smooth enough\" depending on one's perspective), we may be able to then prove continuity and even certain levels of classic differentiability of the solutions. Such results are often quite technical and very difficult but also very satisfying. I personally prefer to read than to prove these results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948e516d-af02-4673-ba30-ccfdf861acfa",
   "metadata": {},
   "source": [
    "---\n",
    "#### Piecewise ICs and solutions to the heat equation (The Ones Who Help to Set The Sun)\n",
    "---\n",
    "\n",
    "Since the heat equation is to be satisfied for $0<x<\\ell$ and $t>0$, we are emboldened to consider \"rougher\" ICs at $t=0$ in order to define solutions that satisfy, in a pointwise sense, the heat equation.\n",
    "\n",
    "Stepping back, we need to justify that if \n",
    "\n",
    "$$\n",
    "    u(x,t) = \\sum_{k=1}^\\infty c_k  \\exp\\left(-c\\frac{(k\\pi)^2}{\\ell^2} t\\right) \\sin\\left(\\frac{k\\pi x}{\\ell}\\right),\n",
    "$$\n",
    "\n",
    "where the $\\{c_k\\}_{k\\in\\mathbb{N}}$ are computed for a given IC $f$, then \n",
    "\n",
    "$$\n",
    "    u_t = cu_{xx}, \\ 0<x<\\ell, t>0, \n",
    "$$\n",
    "\n",
    "which requires us to justify that the partial derivatives of the series are equal to the series of partial derivatives for the spatial-temporal domain $(0,\\ell)\\times(0,\\infty)$.\n",
    "\n",
    "The basic outline of this justification is as follows:\n",
    "\n",
    "- **Prove the smoothing property.** Specifically, we prove that if $f$ is piecewise continuous, then for each $t>0$, the Fourier sine series for $u(x,t)$ above converges uniformly and belongs to $\\mathcal{C}^\\infty_{p,0}((0,\\ell))$, which is the space of infinitely differentiable functions that are $\\ell$-periodic and equal to zero at $x=0$ and $x=\\ell$.\n",
    "\n",
    "- **Establish the interchangeability of differentiation and summation.** Specifically, we need to prove why the partial derivatives of the series are given by the series of partial derivatives. It is then straightforward to show that the differential equation is satisfied on $(0,\\ell)\\times(0,\\infty)$. \n",
    "\n",
    "Moreover, by the smoothing property, we will also establish that the BCs are satsified. Thus, after we establish the above, we can return to analyzing the one missing piece of the IBVP which is analyzing in what sense $u(\\cdot,t)\\to f$ as $t\\downarrow 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef5ca6f-e4bf-4c05-9602-d89213115076",
   "metadata": {},
   "outputs": [],
   "source": [
    "### To-Do: Example illustrating the smoothing property with $\\ell=1$ and $f(x)$ jumping from\n",
    "### 1 to 2 when x goes from <0.5 to \\geq 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d1cc80-4950-4ee1-8dea-1a8a4a67fc1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4052faec-0049-4a38-9cc8-ac12fb2d8dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b206df2-1a03-4f05-b572-ca5e15d22824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "029d5de9-3c07-4b2e-b159-cc9daf2e7daf",
   "metadata": {},
   "source": [
    "---\n",
    "#### The smoothing property (Sleeping Giant)\n",
    "---\n",
    "\n",
    "The goal here is to establish for $t>0$ that the Fourier sine coefficients for $u(x,t)$ given by $c_k \\exp\\left(-c\\frac{(k\\pi)^2}{\\ell^2} t\\right)$ converge to zero faster than $\\mathcal{O}(1/k^m)$ for any $m\\in\\mathbb{N}$, which establishes, by Theorem 3.3.5 in Section 3.3.8, that $u(x,t)\\in\\mathcal{C}^m_p((0,\\ell))$ for every $m\\in\\mathbb{N}$. \n",
    "\n",
    "Subsequently, since $\\mathcal{C}^\\infty_p((0,\\ell)):=\\bigcap_{m=1}^\\infty \\mathcal{C}^m_p((0,\\ell))$, this establishes that $u$ is \"infinitely smooth\" with periodic BCs. The homogeneity of the BCs is in fact immediate since evaluation of the Fourier sine series at $x=0$ or $x=\\ell$ involves a summation of all zero terms, which establishes that $u\\in \\mathcal{C}^\\infty_{p,0}((0,\\ell))$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba5e578-dece-42d4-9f61-dfe1c0c6c368",
   "metadata": {},
   "source": [
    "First, we need a technical result regarding a bound on functions of the form $g(t)=t^ae^{-bt}$ for $a,b\\in\\mathbb{R}^+$ (i.e., $a$ and $b$ are positive real numbers). Specifically, we determine a bound that depends upon only $a$ and $b$ by identifying a critical point (i.e., a root of the derivative).\n",
    "\n",
    "Let $a,b\\in\\mathbb{R}^+$, $g(t) = t^ae^{-bt}$. Then, \n",
    "\n",
    "$$\n",
    "    g(0)=0, \\ \\lim_{t\\to\\infty} g(t)=0, \n",
    "$$\n",
    "\n",
    "and by the product and chain rule, we have\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    g'(t) &= at^{a-1}e^{-bt} - bt^ae^{-bt} \\\\ \\\\\n",
    "          &= t^{a-1}e^{-bt}(a-bt).\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "In $(0,\\infty)$, the derivative, $g'(t)$, is equal to zero only when $a-bt=0$, i.e., when $t=a/b$. It is also straightforward to see that $t^{a-1}e^{-bt}>0$ for all $t>0$ whereas $a-bt$ is positive for $t\\in(0,a/b)$ and is negative for $t\\in(a/b,\\infty)$. Thus, the function achieves its global maximum at $t=a/b$. It follows that\n",
    "\n",
    "$$\n",
    "    M = g(b/a) = \\left(\\frac{a}{b}\\right)e^{-a}\n",
    "$$\n",
    "\n",
    "is a ***bound*** for the function $g(t)$ for all $t\\geq 0$. We make use of this below.\n",
    "\n",
    "With this result, we have that for a given $m\\in\\mathbb{N}$ and $t\\geq 0$, there exists a constant $M$ such that for every $k\\in\\mathbb{N}$, \n",
    "\n",
    "$$\n",
    "    k^{2m}\\exp\\left(-2c\\frac{(k\\pi)^2}{\\ell^2} t\\right) \\leq M.\n",
    "$$\n",
    "\n",
    "<mark>***It is critically important that the $M$ above does not depend upon $k$. It holds for all $k\\in\\mathbb{N}$.***</mark>\n",
    "\n",
    "This immediately implies\n",
    "\n",
    "$$\n",
    "    \\sum_{k=1}^\\infty \\frac{(k\\pi)^{2m}}{\\ell^{4m}}c_k^2 \\exp\\left(-2c\\frac{(k\\pi)^2}{\\ell^2} t\\right) \\leq M \\sum_{k=1}^\\infty c_k^2.\n",
    "$$\n",
    "\n",
    "If we can show that\n",
    "\n",
    "$$\n",
    "    M \\sum_{k=1}^\\infty c_k^2 <\\infty, \n",
    "$$\n",
    "\n",
    "then this implies\n",
    "\n",
    "$$\n",
    "    \\sum_{k=1}^\\infty \\frac{(k\\pi)^{2m}}{\\ell^{4m}}c_k^2 \\exp\\left(-2c\\frac{(k\\pi)^2}{\\ell^2} t\\right) <\\infty, \n",
    "$$\n",
    "\n",
    "which in turn implies that the $m$th partial derivative of $u$ with respect to $x$ exists and is continuous by Theorem 3.3.5. To do this, we wish to relate this to the $L^2((0,\\ell))$ norm of $f$ so that we can conclude $c_k\\sim \\mathcal{O}(1/k^m)$. To do this, we wish to use [Bessel's inequality](https://en.wikipedia.org/wiki/Bessel%27s_inequality), which requires us to first orthonormalize the sine functions in the Fourier sine series expansion used to represent $f$. To this end, observe that\n",
    "\n",
    "$$\n",
    "    f(x) = \\sum_{k=1}^\\infty c_k\\sin(k\\pi x/\\ell) \\Longrightarrow f(x) = \\frac{\\ell}{2}\\sum_{k=1}^\\infty c_k\\frac{\\sin(k\\pi x/\\ell)}{\\ell/2}.\n",
    "$$\n",
    "\n",
    "Now, $\\left\\{\\frac{\\sin(k\\pi x/\\ell)}{\\ell/2}\\right\\}_{k\\in\\mathbb{N}}$ defines an orthonormal sequence in $L^2((0,\\ell))$, from which Bessel's inequality implies\n",
    "\n",
    "$$\n",
    "    M\\sum_{k=1}^\\infty c_k^2 \\leq M\\frac{2}{\\ell} \\|f\\|_{L^2((0,\\ell))}^2 <\\infty.\n",
    "$$\n",
    "\n",
    "This finishes the proof of the following result.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953f1fda-1832-44b1-8a0d-827f3c36c31a",
   "metadata": {},
   "source": [
    "---\n",
    "#### Theorem 3.3.6: Smoothness of solutions\n",
    "\n",
    "Assume $f$ is piecewise continuous on $(0,\\ell)$, which implies it is in $L^2((0,\\ell))$. For each $t>0$, the Fourier sine series defining the formal solution to the heat equation with homogeneous Dirichlet BCs converges uniformly to a function $u(\\cdot, t)\\in \\mathcal{C}^\\infty_{p,0}$.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b93bf3d-06be-4e03-9a67-dce4b63713d3",
   "metadata": {},
   "source": [
    "---\n",
    "#### Interchanging summation and differentiation (These Walls)\n",
    "---\n",
    "\n",
    "The proof of Theorem 3.3.6 relies upon Theorem 3.3.5. It follows that\n",
    "\n",
    "$$\n",
    "    u_N(x,t) := \\sum_{k=1}^N c_k \\exp\\left(-c\\frac{(k\\pi)^2}{\\ell^2} t\\right) \\sin\\left(\\frac{k\\pi x}{\\ell}\\right)\n",
    "$$\n",
    "\n",
    "along with all of its partial derivatives with respect to $x$ converge uniformly to the same partial derivatives with respect to $x$ of $u(x,t)$ for $t>0$. This implies the interchangeability of summation and differentiation with respect to $x$ (i.e., that the derivatives with respect to $x$ of the series is the same thing as the series of derivatives with respect to $x$). \n",
    "\n",
    "What about differentiation with respect to $t$?\n",
    "\n",
    "The goal is to prove that for $t>0$, $\\partial_t u_N(x,t) \\to u_t(x,t)$ (i.e., that the derivatives with respect to $t$ of the series is teh same thing as the series of derivatives with respect to $t$).\n",
    "\n",
    "Once we have this result, it follows that\n",
    "\n",
    "$$\n",
    "    u_t = \\lim_{N\\to\\infty} \\partial_t u_N(x,t) = c\\lim_{N\\to\\infty} \\partial_{xx} u_N(x,t) = cu_{xx}, \n",
    "$$\n",
    "\n",
    "which establishes that the heat equation is satisfied for all $t>0$.\n",
    "\n",
    "Notice that\n",
    "\n",
    "$$\n",
    "    \\partial_t u_N(x,t) = \\sum_{k=1}^N c_k\\left(-c\\frac{(k\\pi)^2}{\\ell^2}\\right)\\exp\\left(-c\\frac{(k\\pi)^2}{\\ell^2} t\\right) \\sin\\left(\\frac{k\\pi x}{\\ell}\\right).\n",
    "$$\n",
    "\n",
    "The $-c$ can be factored out resulting in $c\\partial_{xx}u_N(x,t)$. It follows that $\\partial_t u_N(x,t)\\to u_{xx}$ uniformly. \n",
    "\n",
    "Does this mean that $u_t$ exists and is equal to $\\lim_{N\\to\\infty} \\partial_t S_N(x,t)$?\n",
    "\n",
    "A result from elementary analysis says yes. Specifically, if a sequence of continuously differentiable functions converges uniformly to a continuous function *and* the sequence of derivatives converges uniformly to some function, then the limit function is itself continuously differentiable with derivative equal to the limit of the sequence of derivatives. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a1a4b3-b7c7-4548-b657-18cb30a01a87",
   "metadata": {},
   "source": [
    "---\n",
    "#### Theorem 3.3.7: Justified Fourier Sine Series Solutions to the Heat Equation\n",
    "\n",
    "Assume that $f$ is a piecewise continuous IC to the homogeneous Dirichlet heat equation and $u(x,t)$ given by the Fourier sine series\n",
    "\n",
    "$$\n",
    "    u(x,t) = \\sum_{k=1}^\\infty c_k  \\exp\\left(-c\\frac{(k\\pi)^2}{\\ell^2} t\\right) \\sin\\left(\\frac{k\\pi x}{\\ell}\\right),\n",
    "$$\n",
    "\n",
    "where the $\\{c_k\\}_{k\\in\\mathbb{N}}$ are the Fourier sine coefficients for $f$, then \n",
    "\n",
    "$$\n",
    "    u_t = cu_{xx}, \\ 0<x<\\ell, t>0, \n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "    u(0,t)=u(\\ell,t)=0, \\ t>0.\n",
    "$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e60c51-0a08-4ebc-a834-b010c2f1dd45",
   "metadata": {},
   "source": [
    "What about other types of BCs that lead to other types of \"formal\" Fourier series solutions that need to be made rigorous? Well, a similar type of analysis as above applies to proving the solutions are indeed solutions to the heat equation and satisfy the BCs for all $t>0$. The details of what needs to change in the above analysis are left to the interested reader. We instead return to addressing in what sense $u(\\cdot,t)\\to f$ as $t\\downarrow 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3bd7f6-3925-441d-bf0f-9085d8387d17",
   "metadata": {},
   "source": [
    "---\n",
    "#### The IC\n",
    "---\n",
    "\n",
    "We aim to show that $u(\\cdot, t)\\to f$ in $L^2((0,e\\ll))$ as $t\\downarrow 0$.\n",
    "\n",
    "For any $t>0$, we have from Bessel's inequality that\n",
    "\n",
    "$$\n",
    "    \\|u(x,t) - f(x)\\|_{L^2((0,\\ell))}^2 = \\frac{\\ell}{2}\\sum_{k=1}^\\infty c_k^2\\left(1-\\exp\\left(-c\\frac{(k\\pi)^2}{\\ell^2} t\\right)\\right)^2.\n",
    "$$\n",
    "\n",
    "We achieve our aim once we show that this converges to $0$ as $t\\downarrow 0$. To do this, we let $\\epsilon>0$ and aim to establish the existence of a $T$ such that $0\\leq t<T$ implies the above summation is less than $\\epsilon$.\n",
    "\n",
    "First note that $\\sum_{k=1}^\\infty c_k^2<\\infty$ (previously established), which implies the existence of an $N$ such that $\\sum_{k=N+1}^\\infty c_k^2 < \\epsilon/\\ell$. Choose such an $N$.\n",
    "\n",
    "Now that $N$ is fixed, we note that $0\\leq 1-\\exp\\left(-c\\frac{(k\\pi)^2}{\\ell^2} t\\right) <1$ for all $t\\geq 0$, so \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\frac{\\ell}{2}\\sum_{k=1}^\\infty c_k^2\\left(1-\\exp\\left(-c\\frac{(k\\pi)^2}{\\ell^2} t\\right)\\right)^2 &= \\frac{\\ell}{2} \\left(\\sum_{k=1}^N  c_k^2\\left(1-\\exp\\left(-c\\frac{(k\\pi)^2}{\\ell^2} t\\right)\\right)^2 + \\sum_{k=N+1}^\\infty  c_k^2\\left(1-\\exp\\left(-c\\frac{(k\\pi)^2}{\\ell^2} t\\right)\\right)^2 \\right) \\\\ \\\\\n",
    "      &< \\frac{\\ell}{2} \\left(\\sum_{k=1}^N  c_k^2\\left(1-\\exp\\left(-c\\frac{(k\\pi)^2}{\\ell^2} t\\right)\\right)^2 + \\sum_{k=N+1}^\\infty  c_k^2 \\right) \\\\ \\\\\n",
    "      &< \\left(\\frac{\\ell}{2} \\sum_{k=1}^N  c_k^2\\left(1-\\exp\\left(-c\\frac{(k\\pi)^2}{\\ell^2} t\\right)\\right)^2\\right) + \\frac{\\epsilon}{2}.\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "As $t\\downarrow 0$, for each $k\\in\\mathbb{N}$, we have\n",
    "\n",
    "$$\n",
    "    1-\\exp\\left(-c\\frac{(k\\pi)^2}{\\ell^2} t\\right) \\downarrow 0. \n",
    "$$\n",
    "\n",
    "Thus, we can choose $T_k$ for each $k$ such that $0\\leq t<T_k$ implies \n",
    "\n",
    "$$\n",
    "    0\\leq 1-\\exp\\left(-c\\frac{(k\\pi)^2}{\\ell^2} t\\right) < \\frac{\\epsilon}{N\\ell}.\n",
    "$$\n",
    "\n",
    "Choosing $T=\\min\\{T_1,\\ldots, T_N\\}$ finishes the proof. We summarize below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1887fd-0b94-4e31-914a-85d7f74bd0e4",
   "metadata": {},
   "source": [
    "---\n",
    "#### Theorem 3.3.8: Theory of Fourier Sine Solutions to the Heat Equation (Peruvian Skies)\n",
    "\n",
    "Assume that $f$ is a piecewise continuous IC to the homogeneous Dirichlet heat equation and $u(x,t)$ given by the Fourier sine series\n",
    "\n",
    "$$\n",
    "    u(x,t) = \\sum_{k=1}^\\infty c_k  \\exp\\left(-c\\frac{(k\\pi)^2}{\\ell^2} t\\right) \\sin\\left(\\frac{k\\pi x}{\\ell}\\right),\n",
    "$$\n",
    "\n",
    "where the $\\{c_k\\}_{k\\in\\mathbb{N}}$ are the Fourier sine coefficients for $f$, then \n",
    "\n",
    "$$\n",
    "    u_t = cu_{xx}, \\ 0<x<\\ell, t>0, \n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "    u(0,t)=u(\\ell,t)=0, \\ t>0.\n",
    "$$\n",
    "\n",
    "Moreover, $u(\\cdot, t)\\to f$ in $L^2((0,\\ell))$.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a64b7e-a449-46cc-83cd-eb8cbe4354c7",
   "metadata": {},
   "source": [
    "---\n",
    "## Navigation\n",
    "\n",
    "- [Previous](Chp3Sec2.ipynb)\n",
    "\n",
    "- [Next](Chp3Sec4.ipynb)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
